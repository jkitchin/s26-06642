{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 04: Dimensionality Reduction\n",
    "\n",
    "Techniques for exploring and visualizing high-dimensional data.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Understand why dimensionality reduction is useful\n",
    "2. Apply PCA for linear dimensionality reduction\n",
    "3. Use t-SNE for visualization\n",
    "4. Interpret reduced representations\n",
    "5. Apply to chemical engineering datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Curse of Dimensionality\n",
    "\n",
    "Real datasets often have many features:\n",
    "- Process data: 100s of sensor readings\n",
    "- Spectroscopy: 1000s of wavelengths\n",
    "- Molecular descriptors: 100s of properties\n",
    "\n",
    "Problems with high dimensions:\n",
    "- Hard to visualize\n",
    "- Many features may be correlated\n",
    "- Models can overfit\n",
    "- Distance metrics become less meaningful\n",
    "\n",
    "**Dimensionality reduction** finds a lower-dimensional representation that preserves important structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic catalyst characterization data\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "# Three types of catalysts with different properties\n",
    "catalyst_type = np.random.choice(['Type_A', 'Type_B', 'Type_C'], n_samples)\n",
    "\n",
    "# Base properties for each type\n",
    "base_props = {\n",
    "    'Type_A': [100, 50, 0.8, 300, 25, 1.2, 0.05, 2.5],\n",
    "    'Type_B': [150, 30, 0.5, 250, 35, 0.8, 0.08, 3.0],\n",
    "    'Type_C': [80, 70, 0.9, 350, 20, 1.5, 0.03, 2.0]\n",
    "}\n",
    "\n",
    "# Generate features with noise\n",
    "features = []\n",
    "for cat in catalyst_type:\n",
    "    base = np.array(base_props[cat])\n",
    "    noise = np.random.normal(0, 0.1, len(base)) * base\n",
    "    features.append(base + noise)\n",
    "\n",
    "# Create DataFrame\n",
    "feature_names = ['surface_area', 'pore_volume', 'acidity', 'crystallite_size',\n",
    "                 'metal_dispersion', 'reduction_temp', 'impurity_level', 'particle_size']\n",
    "\n",
    "df = pd.DataFrame(features, columns=feature_names)\n",
    "df['catalyst_type'] = catalyst_type\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 8 dimensions is hard!\n",
    "# Let's look at pairwise relationships\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "colors = {'Type_A': 'blue', 'Type_B': 'red', 'Type_C': 'green'}\n",
    "\n",
    "pairs = [('surface_area', 'pore_volume'), ('acidity', 'crystallite_size'),\n",
    "         ('metal_dispersion', 'reduction_temp'), ('surface_area', 'acidity'),\n",
    "         ('pore_volume', 'particle_size'), ('impurity_level', 'metal_dispersion')]\n",
    "\n",
    "for ax, (x, y) in zip(axes.flat, pairs):\n",
    "    for cat in ['Type_A', 'Type_B', 'Type_C']:\n",
    "        mask = df['catalyst_type'] == cat\n",
    "        ax.scatter(df.loc[mask, x], df.loc[mask, y], c=colors[cat], label=cat, alpha=0.6)\n",
    "    ax.set_xlabel(x)\n",
    "    ax.set_ylabel(y)\n",
    "\n",
    "axes[0, 0].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "\n",
    "PCA finds orthogonal directions of maximum variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data: extract features and scale\n",
    "X = df[feature_names].values\n",
    "y = df['catalyst_type'].values\n",
    "\n",
    "# Scaling is important for PCA!\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Original shape: {X.shape}\")\n",
    "print(f\"Mean of scaled data: {X_scaled.mean(axis=0).round(2)}\")\n",
    "print(f\"Std of scaled data: {X_scaled.std(axis=0).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Explained variance\n",
    "print(\"Explained variance ratio per component:\")\n",
    "for i, var in enumerate(pca.explained_variance_ratio_):\n",
    "    print(f\"  PC{i+1}: {var:.3f} ({var*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nCumulative variance with 2 components: {pca.explained_variance_ratio_[:2].sum():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scree plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Individual variance\n",
    "axes[0].bar(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "            pca.explained_variance_ratio_, edgecolor='black')\n",
    "axes[0].set_xlabel('Principal Component')\n",
    "axes[0].set_ylabel('Explained Variance Ratio')\n",
    "axes[0].set_title('Scree Plot')\n",
    "\n",
    "# Cumulative variance\n",
    "cumulative = np.cumsum(pca.explained_variance_ratio_)\n",
    "axes[1].plot(range(1, len(cumulative) + 1), cumulative, 'o-')\n",
    "axes[1].axhline(y=0.9, color='r', linestyle='--', label='90% threshold')\n",
    "axes[1].set_xlabel('Number of Components')\n",
    "axes[1].set_ylabel('Cumulative Explained Variance')\n",
    "axes[1].set_title('Cumulative Variance')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize in 2D\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for cat in ['Type_A', 'Type_B', 'Type_C']:\n",
    "    mask = y == cat\n",
    "    plt.scatter(X_pca[mask, 0], X_pca[mask, 1], label=cat, alpha=0.6, s=50)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('PCA of Catalyst Properties')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret principal components: loadings\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=[f'PC{i+1}' for i in range(len(feature_names))],\n",
    "    index=feature_names\n",
    ")\n",
    "\n",
    "print(\"PC Loadings (contribution of each feature):\")\n",
    "print(loadings[['PC1', 'PC2', 'PC3']].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biplot: visualize samples and loadings together\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Plot samples\n",
    "for cat in ['Type_A', 'Type_B', 'Type_C']:\n",
    "    mask = y == cat\n",
    "    ax.scatter(X_pca[mask, 0], X_pca[mask, 1], label=cat, alpha=0.5, s=30)\n",
    "\n",
    "# Plot loadings as arrows\n",
    "scale = 3  # Scale factor for visibility\n",
    "for i, feature in enumerate(feature_names):\n",
    "    ax.arrow(0, 0, loadings.iloc[i, 0]*scale, loadings.iloc[i, 1]*scale,\n",
    "             head_width=0.1, head_length=0.05, fc='black', ec='black')\n",
    "    ax.text(loadings.iloc[i, 0]*scale*1.1, loadings.iloc[i, 1]*scale*1.1, \n",
    "            feature, fontsize=9)\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "ax.set_title('PCA Biplot')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE: Nonlinear Visualization\n",
    "\n",
    "t-SNE preserves local structure and is better for visualization of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for cat in ['Type_A', 'Type_B', 'Type_C']:\n",
    "    mask = y == cat\n",
    "    plt.scatter(X_tsne[mask, 0], X_tsne[mask, 1], label=cat, alpha=0.6, s=50)\n",
    "\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.title('t-SNE of Catalyst Properties')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of perplexity\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for ax, perp in zip(axes, [5, 30, 100]):\n",
    "    tsne = TSNE(n_components=2, perplexity=perp, random_state=42)\n",
    "    X_tsne = tsne.fit_transform(X_scaled)\n",
    "    \n",
    "    for cat in ['Type_A', 'Type_B', 'Type_C']:\n",
    "        mask = y == cat\n",
    "        ax.scatter(X_tsne[mask, 0], X_tsne[mask, 1], label=cat, alpha=0.6)\n",
    "    \n",
    "    ax.set_title(f'Perplexity = {perp}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA vs t-SNE\n",
    "\n",
    "| Aspect | PCA | t-SNE |\n",
    "|--------|-----|-------|\n",
    "| Type | Linear | Nonlinear |\n",
    "| Preserves | Global structure | Local structure |\n",
    "| Interpretable | Yes (loadings) | No |\n",
    "| Speed | Fast | Slow |\n",
    "| New data | Can project | Cannot project |\n",
    "| Use for | Features, preprocessing | Visualization |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# PCA\n",
    "for cat in ['Type_A', 'Type_B', 'Type_C']:\n",
    "    mask = y == cat\n",
    "    axes[0].scatter(X_pca[mask, 0], X_pca[mask, 1], label=cat, alpha=0.6, s=50)\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "axes[0].set_title('PCA')\n",
    "axes[0].legend()\n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "for cat in ['Type_A', 'Type_B', 'Type_C']:\n",
    "    mask = y == cat\n",
    "    axes[1].scatter(X_tsne[mask, 0], X_tsne[mask, 1], label=cat, alpha=0.6, s=50)\n",
    "axes[1].set_xlabel('t-SNE 1')\n",
    "axes[1].set_ylabel('t-SNE 2')\n",
    "axes[1].set_title('t-SNE')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PCA for Feature Reduction\n",
    "\n",
    "PCA can be used as a preprocessing step before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep components that explain 90% of variance\n",
    "pca_90 = PCA(n_components=0.90)\n",
    "X_reduced = pca_90.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Original features: {X_scaled.shape[1]}\")\n",
    "print(f\"Reduced features: {X_reduced.shape[1]}\")\n",
    "print(f\"Explained variance: {pca_90.explained_variance_ratio_.sum():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Technique | Use Case |\n",
    "|-----------|----------|\n",
    "| PCA | Feature reduction, preprocessing, interpretable visualization |\n",
    "| t-SNE | Cluster visualization, exploring structure |\n",
    "\n",
    "Key points:\n",
    "- Always scale your data before dimensionality reduction\n",
    "- Check explained variance to choose number of components\n",
    "- Use loadings to interpret PCA components\n",
    "- t-SNE is for visualization only (don't use distances meaningfully)\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now we'll learn how to build predictive models using linear regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
