{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: LLMs for Scientific Research\n",
    "\n",
    "Using Large Language Models in research workflows.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Understand LLM capabilities and limitations\n",
    "2. Use APIs for text processing\n",
    "3. Extract information from scientific text\n",
    "4. Generate and improve scientific writing\n",
    "5. Apply to code generation and debugging"
   ]
  },
  {
   "cell_type": "code",
   "source": "! pip install -q pycse\nfrom pycse.colab import pdf",
   "metadata": {
    "tags": [
     "skip-execution",
     "remove-cell"
    ]
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# APIs require keys - set as environment variables\n",
    "# export OPENAI_API_KEY=\"your-key\"\n",
    "# export ANTHROPIC_API_KEY=\"your-key\"\n",
    "\n",
    "try:\n",
    "    import openai\n",
    "    OPENAI_AVAILABLE = True\n",
    "except ImportError:\n",
    "    OPENAI_AVAILABLE = False\n",
    "    print(\"OpenAI not installed. Run: pip install openai\")\n",
    "\n",
    "try:\n",
    "    import anthropic\n",
    "    ANTHROPIC_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ANTHROPIC_AVAILABLE = False\n",
    "    print(\"Anthropic not installed. Run: pip install anthropic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Capabilities for Research\n",
    "\n",
    "| Task | Use Case | Reliability |\n",
    "|------|----------|-------------|\n",
    "| Text summarization | Literature review | High |\n",
    "| Information extraction | Data mining papers | Medium |\n",
    "| Writing assistance | Manuscript editing | High |\n",
    "| Code generation | Prototyping | Medium |\n",
    "| Code debugging | Error explanation | High |\n",
    "| Brainstorming | Research ideas | Medium |\n",
    "| Math/calculations | Numerical work | Low - verify! |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Information extraction from abstract\n",
    "abstract = \"\"\"\n",
    "We investigated the catalytic hydrogenation of CO2 to methanol over Cu/ZnO/Al2O3 \n",
    "catalysts at temperatures ranging from 200-300°C and pressures of 30-50 bar. \n",
    "The catalyst with 10 wt% Cu loading achieved the highest methanol selectivity \n",
    "of 85% at 250°C and 40 bar, with a CO2 conversion of 23%. Characterization by \n",
    "XRD and TPR revealed that the optimal Cu dispersion was achieved at this loading.\n",
    "\"\"\"\n",
    "\n",
    "# Extraction prompt\n",
    "extraction_prompt = f\"\"\"\n",
    "Extract the following information from this abstract:\n",
    "1. Catalyst composition\n",
    "2. Temperature range\n",
    "3. Pressure range  \n",
    "4. Best performance conditions\n",
    "5. Key metrics (conversion, selectivity)\n",
    "\n",
    "Abstract: {abstract}\n",
    "\n",
    "Format as JSON.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Prompt for information extraction:\")\n",
    "print(extraction_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Code generation prompt\n",
    "code_prompt = \"\"\"\n",
    "Write a Python function that:\n",
    "1. Takes temperature (K) and pressure (bar) as inputs\n",
    "2. Calculates the compressibility factor Z using the van der Waals equation\n",
    "3. Uses a=3.64 L²bar/mol² and b=0.0427 L/mol for CO2\n",
    "4. Returns Z\n",
    "\n",
    "Include docstring and type hints.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Code generation prompt:\")\n",
    "print(code_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "1. **Be specific**: Clear prompts get better results\n",
    "2. **Verify outputs**: Never trust LLM calculations blindly\n",
    "3. **Iterate**: Refine prompts based on results\n",
    "4. **Use examples**: Show the format you want\n",
    "5. **Chain tasks**: Break complex work into steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example API call structure (requires API key)\n",
    "def call_claude(prompt, api_key=None):\n",
    "    \"\"\"Call Claude API with a prompt.\"\"\"\n",
    "    if not ANTHROPIC_AVAILABLE:\n",
    "        return \"Anthropic library not installed\"\n",
    "    \n",
    "    if api_key is None:\n",
    "        api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "    \n",
    "    if not api_key:\n",
    "        return \"API key not set\"\n",
    "    \n",
    "    client = anthropic.Anthropic(api_key=api_key)\n",
    "    \n",
    "    message = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return message.content[0].text\n",
    "\n",
    "# Uncomment to test (requires API key)\n",
    "# result = call_claude(\"What is the ideal gas law?\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "\n",
    "- **Hallucinations**: LLMs can make up facts and citations\n",
    "- **Math errors**: Don't trust numerical calculations\n",
    "- **Knowledge cutoff**: May not know recent work\n",
    "- **Context length**: Can't process very long documents\n",
    "- **Reproducibility**: Outputs vary between calls\n",
    "\n",
    "## Responsible Use\n",
    "\n",
    "- Always verify facts and calculations\n",
    "- Cite sources properly (LLM output isn't a source)\n",
    "- Use as a tool, not a replacement for understanding\n",
    "- Follow institutional policies on AI use"
   ]
  },
  {
   "cell_type": "code",
   "source": "! pip install -q jupyterquiz\nfrom jupyterquiz import display_quiz\n\ndisplay_quiz(\"https://raw.githubusercontent.com/jkitchin/s26-06642/main/dsmles/optional/quizzes/llms-quiz.json\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "LLMs are powerful tools for:\n",
    "- Literature review and summarization\n",
    "- Code generation and debugging\n",
    "- Writing assistance\n",
    "\n",
    "But require:\n",
    "- Careful verification\n",
    "- Domain expertise to evaluate outputs\n",
    "- Responsible use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}