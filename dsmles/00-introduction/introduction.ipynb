{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jkitchin/s26-06642/blob/main/dsmles/00-introduction/introduction.ipynb)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 00: Introduction\n",
    "\n",
    "Welcome to Data Science and Machine Learning in Chemical Engineering!\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will:\n",
    "1. Understand the scope and goals of the course\n",
    "2. Set up your Python environment\n",
    "3. Review essential Python concepts\n",
    "4. Understand the machine learning workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Data Science in Chemical Engineering?\n",
    "\n",
    "Chemical engineers increasingly work with data:\n",
    "\n",
    "- **Process data**: Sensor readings, control systems, quality measurements\n",
    "- **Experimental data**: Lab results, catalyst testing, reaction optimization\n",
    "- **Simulation data**: CFD, molecular dynamics, process modeling\n",
    "- **Literature data**: Published properties, kinetic parameters, correlations\n",
    "\n",
    "Machine learning provides tools to:\n",
    "1. **Find patterns** in complex, high-dimensional data\n",
    "2. **Build predictive models** without explicit physical equations\n",
    "3. **Optimize processes** based on data-driven insights\n",
    "4. **Quantify uncertainty** in predictions and measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Overview\n",
    "\n",
    "### Data Foundations (Modules 01-03)\n",
    "- NumPy for numerical computing\n",
    "- Pandas for data manipulation\n",
    "- Visualization with Matplotlib\n",
    "\n",
    "### Core Machine Learning (Modules 04-08)\n",
    "- Dimensionality reduction (PCA, t-SNE)\n",
    "- Regression (linear, regularized, nonlinear)\n",
    "- Ensemble methods (Random Forests, Gradient Boosting)\n",
    "\n",
    "### Advanced Topics (Modules 09-11)\n",
    "- Clustering for unsupervised learning\n",
    "- Uncertainty quantification\n",
    "- Model interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Environment Setup\n\n### Option 1: uv (Recommended)\n\n[uv](https://docs.astral.sh/uv/) is a fast Python package manager. Install it first:\n\n```bash\n# macOS/Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Windows\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\nThen set up the project:\n\n```bash\n# Clone the course repository and cd into it\nuv sync  # Creates virtual environment and installs all dependencies\n\n# Activate the environment\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n\n# Start JupyterLab\njupyter lab\n```\n\n### Option 2: Google Colab\n\nOpen notebooks directly in Colab using the rocket icon at the top of each page."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Installation\n",
    "\n",
    "Run the following cell to check that everything is installed correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pycse\n",
    "import shap\n",
    "import xgboost\n",
    "\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"Scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"XGBoost: {xgboost.__version__}\")\n",
    "print(\"\\nAll packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Refresher\n",
    "\n",
    "### Lists and Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of experimental temperatures (Kelvin)\n",
    "temperatures = [300, 350, 400, 450, 500]\n",
    "\n",
    "# Convert to Celsius using a loop\n",
    "temps_celsius = []\n",
    "for T in temperatures:\n",
    "    temps_celsius.append(T - 273.15)\n",
    "\n",
    "print(\"Celsius:\", temps_celsius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better: List comprehension\n",
    "temps_celsius = [T - 273.15 for T in temperatures]\n",
    "print(\"Celsius:\", temps_celsius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store experiment parameters\n",
    "experiment = {\n",
    "    'temperature': 400,  # K\n",
    "    'pressure': 101.325,  # kPa\n",
    "    'catalyst': 'Pt/Al2O3',\n",
    "    'conversion': 0.85\n",
    "}\n",
    "\n",
    "print(f\"At {experiment['temperature']} K, conversion was {experiment['conversion']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrhenius_rate(T, A=1e13, Ea=80000, R=8.314):\n",
    "    \"\"\"\n",
    "    Calculate reaction rate constant using Arrhenius equation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    T : float\n",
    "        Temperature in Kelvin\n",
    "    A : float\n",
    "        Pre-exponential factor (1/s)\n",
    "    Ea : float\n",
    "        Activation energy (J/mol)\n",
    "    R : float\n",
    "        Gas constant (J/mol/K)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Rate constant k\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    return A * np.exp(-Ea / (R * T))\n",
    "\n",
    "# Calculate rate at different temperatures\n",
    "for T in [300, 400, 500]:\n",
    "    k = arrhenius_rate(T)\n",
    "    print(f\"k({T} K) = {k:.2e} 1/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Machine Learning Workflow\n",
    "\n",
    "Most ML projects follow this pattern:\n",
    "\n",
    "```\n",
    "1. Define the problem\n",
    "   ↓\n",
    "2. Collect and explore data\n",
    "   ↓\n",
    "3. Prepare data (cleaning, feature engineering)\n",
    "   ↓\n",
    "4. Choose and train models\n",
    "   ↓\n",
    "5. Evaluate and validate\n",
    "   ↓\n",
    "6. Interpret and communicate\n",
    "   ↓\n",
    "7. Deploy (if applicable)\n",
    "```\n",
    "\n",
    "This course covers steps 2-6, with emphasis on chemical engineering applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Predicting Reaction Yield\n",
    "\n",
    "Let's preview what we'll be able to do by the end of the course.\n",
    "\n",
    "**Problem**: Predict reaction yield from experimental conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic experiment data\n",
    "np.random.seed(42)\n",
    "n_experiments = 100\n",
    "\n",
    "# Experimental conditions\n",
    "temperature = np.random.uniform(300, 500, n_experiments)  # K\n",
    "pressure = np.random.uniform(1, 10, n_experiments)  # atm\n",
    "catalyst_loading = np.random.uniform(0.01, 0.10, n_experiments)  # wt%\n",
    "\n",
    "# \"True\" yield model (unknown to us in practice)\n",
    "yield_true = (\n",
    "    50 + \n",
    "    0.1 * (temperature - 400) + \n",
    "    2 * pressure + \n",
    "    100 * catalyst_loading +\n",
    "    np.random.normal(0, 3, n_experiments)  # noise\n",
    ")\n",
    "yield_true = np.clip(yield_true, 0, 100)  # Yield between 0-100%\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'temperature': temperature,\n",
    "    'pressure': pressure,\n",
    "    'catalyst_loading': catalyst_loading,\n",
    "    'yield': yield_true\n",
    "})\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "axes[0].scatter(data['temperature'], data['yield'], alpha=0.5)\n",
    "axes[0].set_xlabel('Temperature (K)')\n",
    "axes[0].set_ylabel('Yield (%)')\n",
    "\n",
    "axes[1].scatter(data['pressure'], data['yield'], alpha=0.5)\n",
    "axes[1].set_xlabel('Pressure (atm)')\n",
    "axes[1].set_ylabel('Yield (%)')\n",
    "\n",
    "axes[2].scatter(data['catalyst_loading'], data['yield'], alpha=0.5)\n",
    "axes[2].set_xlabel('Catalyst Loading (wt%)')\n",
    "axes[2].set_ylabel('Yield (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple model (we'll learn this properly later!)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Prepare data\n",
    "X = data[['temperature', 'pressure', 'catalyst_loading']]\n",
    "y = data['yield']\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}%\")\n",
    "print(f\"R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([40, 80], [40, 80], 'r--', label='Perfect prediction')\n",
    "plt.xlabel('Actual Yield (%)')\n",
    "plt.ylabel('Predicted Yield (%)')\n",
    "plt.title('Model Performance')\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next\n",
    "\n",
    "In the upcoming modules, we'll learn:\n",
    "\n",
    "1. **NumPy** - How to work with numerical data efficiently\n",
    "2. **Pandas** - How to load, clean, and manipulate data\n",
    "3. **Visualization** - How to explore and present data\n",
    "4. **Regression** - How to build and validate predictive models\n",
    "5. **Advanced methods** - How to handle complex, nonlinear relationships\n",
    "6. **Uncertainty** - How to quantify confidence in predictions\n",
    "7. **Interpretability** - How to understand what the model learned\n",
    "\n",
    "Let's get started with NumPy in the next module!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Data science and ML are increasingly important in chemical engineering\n",
    "- This course covers practical tools: NumPy, Pandas, scikit-learn, and more\n",
    "- We follow a standard ML workflow: data → model → evaluation → interpretation\n",
    "- All examples will use chemical engineering applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}