{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jkitchin/s26-06642/blob/main/dsmles/assignments/project-report.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Final Report\n",
    "\n",
    "**Due Date:** See course schedule  \n",
    "\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The final report is your complete analysis notebook demonstrating mastery of machine learning applied to a chemical engineering problem. This is your opportunity to showcase everything you've learned in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -LsSf https://astral.sh/uv/install.sh | sh && \\\n",
    "  uv pip install -q --system \"s26-06642 @ git+https://github.com/jkitchin/s26-06642.git\"\n",
    "from pycse.colab import pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Structure\n",
    "\n",
    "Your report should follow this structure (approximate page lengths for guidance):\n",
    "\n",
    "1. **Introduction** (1-2 pages)\n",
    "2. **Data** (1-2 pages)\n",
    "3. **Methods** (2-3 pages)\n",
    "4. **Results** (2-3 pages)\n",
    "5. **Discussion** (1-2 pages)\n",
    "6. **Conclusions** (0.5 page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Include:\n",
    "- Problem motivation: Why does this problem matter?\n",
    "- Background and prior work: What has been done before?\n",
    "- Objectives: What specific questions are you answering?\n",
    "\n",
    "*Write your introduction here*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data\n",
    "\n",
    "Include:\n",
    "- Data source and collection method\n",
    "- Feature descriptions (what each column means)\n",
    "- Exploratory data analysis with visualizations\n",
    "- Preprocessing steps (scaling, encoding, missing values, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Load your data\n",
    "# df = pd.read_csv('your_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data overview\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA visualizations\n",
    "# Add distribution plots, correlation heatmaps, scatter plots, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Describe your data and preprocessing steps*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Methods\n",
    "\n",
    "Include:\n",
    "- Model selection rationale: Why did you choose these methods?\n",
    "- Hyperparameter tuning approach\n",
    "- Validation strategy (train/test split, cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "# X = df[feature_columns]\n",
    "# y = df[target_column]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "# Try multiple models and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain your methodology choices*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Results\n",
    "\n",
    "Include:\n",
    "- Model performance metrics (with appropriate metrics for your problem)\n",
    "- Comparison of different methods\n",
    "- Feature importance or model interpretability analysis\n",
    "- Uncertainty quantification (if applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(f\"RÂ² Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "# print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
    "# print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions vs actual plot\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "# plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "# plt.xlabel('Actual')\n",
    "# plt.ylabel('Predicted')\n",
    "# plt.title('Predictions vs Actual')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison table\n",
    "# Create a DataFrame comparing different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "# import shap\n",
    "# or use model.feature_importances_ for tree-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Present and interpret your results*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Discussion\n",
    "\n",
    "Include:\n",
    "- Key findings: What did you learn?\n",
    "- Physical/chemical interpretation: Do the results make sense?\n",
    "- Limitations: What are the weaknesses of your approach?\n",
    "- Future work: What would you do differently or next?\n",
    "\n",
    "*Write your discussion here*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Conclusions\n",
    "\n",
    "Summarize your main contributions and findings in a few sentences.\n",
    "\n",
    "*Write your conclusions here*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What Success Looks Like\n",
    "\n",
    "A successful final report will demonstrate:\n",
    "\n",
    "| Criterion | Expectation |\n",
    "|-----------|-------------|\n",
    "| **Problem Formulation** | Clear, relevant, well-motivated problem |\n",
    "| **Data Analysis** | Thorough EDA with informative visualizations |\n",
    "| **Methodology** | Appropriate methods with proper validation |\n",
    "| **Results** | Clear presentation with proper metrics |\n",
    "| **Interpretation** | Domain insights and meaningful conclusions |\n",
    "| **Communication** | Clear writing, well-organized, good visualizations |\n",
    "| **Code Quality** | Clean, documented, reproducible code |\n",
    "\n",
    "### Excellent Reports Will Also Have\n",
    "\n",
    "- Multiple models compared fairly\n",
    "- Thoughtful hyperparameter tuning\n",
    "- Feature importance or SHAP analysis\n",
    "- Uncertainty quantification\n",
    "- Physical interpretation of results\n",
    "- Honest discussion of limitations\n",
    "\n",
    "### Red Flags (things to avoid)\n",
    "\n",
    "- Code that doesn't run\n",
    "- No train/test split (data leakage)\n",
    "- Only accuracy reported for imbalanced classification\n",
    "- No visualizations\n",
    "- Results that don't make physical sense (and aren't discussed)\n",
    "- Copy-pasted code without understanding\n",
    "- Missing sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission\n",
    "\n",
    "Run the cell below to generate a PDF for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf(\"project-report.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
