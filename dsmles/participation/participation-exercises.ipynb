{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# In-Class Participation Exercises\n",
    "\n",
    "This notebook contains participation activities for each lecture module. Exercises are designed to be completed during class time and encourage active engagement with the material.\n",
    "\n",
    "## Exercise Types\n",
    "\n",
    "| Type | Icon | Description | Time |\n",
    "|------|------|-------------|------|\n",
    "| **Reflection** | :thinking: | Personal reflection on concepts and connections | 3-5 min |\n",
    "| **Mini-Exercise** | :wrench: | Hands-on coding or problem solving | 5-10 min |\n",
    "| **Discussion** | :speech_balloon: | Pair or group discussion with neighbors | 5-7 min |\n",
    "| **Prediction** | :crystal_ball: | Make a prediction before seeing results | 2-3 min |\n",
    "| **Critique** | :mag: | Analyze code, results, or approaches | 5-7 min |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-00",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 00: Introduction\n",
    "\n",
    "## Exercise 0.1: Reflection - Your Data Story\n",
    "\n",
    "**Type:** :thinking: Reflection (3 min writing, 2 min sharing)\n",
    "\n",
    "Think about a time you worked with data (in a class, research, internship, or personal project).\n",
    "\n",
    "1. What was the data about?\n",
    "2. What question were you trying to answer?\n",
    "3. What was the most challenging part?\n",
    "\n",
    "**Share:** Turn to a neighbor and share one insight from your experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-0-1-response",
   "metadata": {},
   "source": [
    "*Your response:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-0-2",
   "metadata": {},
   "source": [
    "## Exercise 0.2: Discussion - ML in Your Field\n",
    "\n",
    "**Type:** :speech_balloon: Discussion (5 min)\n",
    "\n",
    "With 2-3 neighbors, discuss:\n",
    "\n",
    "1. What's one problem in chemical engineering where you think machine learning could help?\n",
    "2. What data would you need to solve it?\n",
    "3. What would success look like?\n",
    "\n",
    "Be prepared to share your group's best idea with the class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-0-2-response",
   "metadata": {},
   "source": [
    "*Group notes:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-0-3",
   "metadata": {},
   "source": [
    "## Exercise 0.3: Prediction - Model Performance\n",
    "\n",
    "**Type:** :crystal_ball: Prediction (2 min)\n",
    "\n",
    "Before we run the introductory example, predict:\n",
    "\n",
    "- If we train a model to predict reaction yield from temperature, pressure, and catalyst loading, what R^2 do you expect?\n",
    "  - [ ] R^2 < 0.5 (poor fit)\n",
    "  - [ ] R^2 = 0.5-0.7 (moderate fit)\n",
    "  - [ ] R^2 = 0.7-0.9 (good fit)\n",
    "  - [ ] R^2 > 0.9 (excellent fit)\n",
    "\n",
    "**Why?** Write one sentence explaining your prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-0-3-response",
   "metadata": {},
   "source": [
    "*Your prediction and reasoning:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-01",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 01: NumPy Fundamentals\n",
    "\n",
    "## Exercise 1.1: Mini-Exercise - Vectorization Challenge\n",
    "\n",
    "**Type:** :wrench: Mini-Exercise (7 min)\n",
    "\n",
    "Convert this loop-based code to vectorized NumPy operations. Time both versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-1-1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given: temperatures in Celsius\n",
    "temps_C = np.array([25, 50, 75, 100, 125, 150, 175, 200])\n",
    "\n",
    "# Loop version (slow) - calculate vapor pressure using Antoine equation\n",
    "# For water: log10(P) = A - B/(C + T), with A=8.07, B=1730.63, C=233.43\n",
    "A, B, C = 8.07, 1730.63, 233.43\n",
    "\n",
    "pressures_loop = []\n",
    "for T in temps_C:\n",
    "    log_P = A - B / (C + T)\n",
    "    P = 10 ** log_P\n",
    "    pressures_loop.append(P)\n",
    "pressures_loop = np.array(pressures_loop)\n",
    "\n",
    "print(\"Loop result:\", pressures_loop)\n",
    "\n",
    "# YOUR TASK: Write the vectorized version below\n",
    "# pressures_vectorized = ???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-1-2",
   "metadata": {},
   "source": [
    "## Exercise 1.2: Discussion - When Loops Are Okay\n",
    "\n",
    "**Type:** :speech_balloon: Discussion (5 min)\n",
    "\n",
    "We learned that vectorization is faster than loops. But are there situations where loops are better or necessary?\n",
    "\n",
    "With a partner, come up with 2-3 scenarios where you might still use a loop in scientific Python code.\n",
    "\n",
    "**Hint:** Think about dependencies between iterations, readability, or operations that can't be vectorized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-1-2-response",
   "metadata": {},
   "source": [
    "*Scenarios where loops might be appropriate:*\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-1-3",
   "metadata": {},
   "source": [
    "## Exercise 1.3: Reflection - Broadcasting Intuition\n",
    "\n",
    "**Type:** :thinking: Reflection (3 min)\n",
    "\n",
    "Broadcasting is one of NumPy's most powerful features, but it can also cause subtle bugs.\n",
    "\n",
    "Look at this code and predict the output shape **without running it**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-1-3-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])  # Shape: (2, 3)\n",
    "\n",
    "B = np.array([10, 20, 30])  # Shape: (3,)\n",
    "\n",
    "C = np.array([[100],\n",
    "              [200]])  # Shape: (2, 1)\n",
    "\n",
    "# Predict shapes before running:\n",
    "# A + B = shape ???\n",
    "# A + C = shape ???\n",
    "# A + B + C = shape ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-1-3-response",
   "metadata": {},
   "source": [
    "*Your predictions:*\n",
    "\n",
    "- A + B = \n",
    "- A + C = \n",
    "- A + B + C = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-02",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 02: Pandas Introduction\n",
    "\n",
    "## Exercise 2.1: Prediction - Data Types\n",
    "\n",
    "**Type:** :crystal_ball: Prediction (3 min)\n",
    "\n",
    "You receive a CSV file with experimental data. Before loading it, predict what data types pandas will assign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-2-1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine this CSV content:\n",
    "csv_content = \"\"\"\n",
    "experiment_id,temperature,pressure,catalyst,yield,date,notes\n",
    "EXP001,350.5,1.2,Pt/Al2O3,78.3,2024-01-15,Good run\n",
    "EXP002,375.0,1.5,Pd/C,82.1,2024-01-16,\n",
    "EXP003,400.0,1.8,Pt/Al2O3,NaN,2024-01-17,Equipment failure\n",
    "\"\"\"\n",
    "\n",
    "# Predict the dtype for each column:\n",
    "# experiment_id: ???\n",
    "# temperature: ???\n",
    "# pressure: ???\n",
    "# catalyst: ???\n",
    "# yield: ???\n",
    "# date: ???\n",
    "# notes: ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-2-1-response",
   "metadata": {},
   "source": [
    "*Your dtype predictions:*\n",
    "\n",
    "| Column | Predicted dtype | Reasoning |\n",
    "|--------|-----------------|--------|\n",
    "| experiment_id | | |\n",
    "| temperature | | |\n",
    "| pressure | | |\n",
    "| catalyst | | |\n",
    "| yield | | |\n",
    "| date | | |\n",
    "| notes | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-2-2",
   "metadata": {},
   "source": [
    "## Exercise 2.2: Mini-Exercise - Data Exploration Race\n",
    "\n",
    "**Type:** :wrench: Mini-Exercise (7 min)\n",
    "\n",
    "Load the dataset below and answer all questions as quickly as possible. First person done raises their hand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-2-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create sample reactor data\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "df = pd.DataFrame({\n",
    "    'reactor': np.random.choice(['R1', 'R2', 'R3'], n),\n",
    "    'temperature': np.random.uniform(300, 500, n),\n",
    "    'pressure': np.random.uniform(1, 10, n),\n",
    "    'conversion': np.random.uniform(0.3, 0.95, n),\n",
    "    'shift': np.random.choice(['Day', 'Night'], n)\n",
    "})\n",
    "df.loc[np.random.choice(n, 5), 'conversion'] = np.nan  # Add some missing values\n",
    "\n",
    "# QUESTIONS - Answer using pandas operations:\n",
    "# 1. How many rows and columns?\n",
    "# 2. How many missing values in 'conversion'?\n",
    "# 3. What is the mean temperature for reactor R2?\n",
    "# 4. How many experiments were run on the Night shift?\n",
    "# 5. What is the maximum conversion?\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-2-3",
   "metadata": {},
   "source": [
    "## Exercise 2.3: Discussion - Missing Data Strategies\n",
    "\n",
    "**Type:** :speech_balloon: Discussion (5 min)\n",
    "\n",
    "You have sensor data from a reactor with 10% missing values. Discuss with a partner:\n",
    "\n",
    "1. What are three different ways to handle the missing data?\n",
    "2. What are the pros and cons of each approach?\n",
    "3. Does it matter *why* the data is missing?\n",
    "\n",
    "**Scenario:** The missing values occur mostly during shift changes. How does this affect your strategy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-2-3-response",
   "metadata": {},
   "source": [
    "*Discussion notes:*\n",
    "\n",
    "| Strategy | Pros | Cons |\n",
    "|----------|------|------|\n",
    "| | | |\n",
    "| | | |\n",
    "| | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-03",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 03: Intermediate Pandas\n",
    "\n",
    "## Exercise 3.1: Mini-Exercise - GroupBy Challenge\n",
    "\n",
    "**Type:** :wrench: Mini-Exercise (8 min)\n",
    "\n",
    "Use groupby operations to answer questions about catalyst performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-3-1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    'catalyst': np.random.choice(['Pt/Al2O3', 'Pd/C', 'Ni/SiO2'], 150),\n",
    "    'temperature': np.random.choice([350, 400, 450], 150),\n",
    "    'yield': np.random.uniform(50, 95, 150),\n",
    "    'selectivity': np.random.uniform(0.7, 0.99, 150)\n",
    "})\n",
    "\n",
    "# TASKS:\n",
    "# 1. Find the mean yield for each catalyst\n",
    "# 2. Find the mean yield for each catalyst-temperature combination\n",
    "# 3. Which catalyst has the highest average selectivity?\n",
    "# 4. Create a pivot table: rows=catalyst, columns=temperature, values=mean yield\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-3-2",
   "metadata": {},
   "source": [
    "## Exercise 3.2: Reflection - Data Wrangling Frustrations\n",
    "\n",
    "**Type:** :thinking: Reflection (3 min)\n",
    "\n",
    "Data wrangling often takes 80% of a data science project's time.\n",
    "\n",
    "1. What's the messiest dataset you've encountered? What made it difficult?\n",
    "2. What would have made your life easier (better data collection, documentation, etc.)?\n",
    "\n",
    "**Connection:** How might you design experiments or data collection to make future analysis easier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-3-2-response",
   "metadata": {},
   "source": [
    "*Your reflection:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-3-3",
   "metadata": {},
   "source": [
    "## Exercise 3.3: Critique - Spot the Bug\n",
    "\n",
    "**Type:** :mag: Critique (5 min)\n",
    "\n",
    "The following code attempts to analyze experimental data but contains several bugs or poor practices. Find and fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-3-3-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "df = pd.DataFrame({\n",
    "    'temp': [350, 400, np.nan, 450, 400],\n",
    "    'yield': [75, 82, 78, np.nan, 85],\n",
    "    'catalyst': ['Pt', 'Pt', 'Pd', 'Pd', 'Pt']\n",
    "})\n",
    "\n",
    "# BUGGY CODE - Find the problems:\n",
    "\n",
    "# Bug 1: Calculate mean yield per catalyst\n",
    "mean_yields = df.groupby('catalyst').mean()['yield']\n",
    "\n",
    "# Bug 2: Filter to high-yield experiments\n",
    "high_yield = df[df.yield > 80]\n",
    "\n",
    "# Bug 3: Fill missing temperatures with the mean\n",
    "df.temp.fillna(df.temp.mean())\n",
    "\n",
    "# Bug 4: Check if there are any missing values left\n",
    "print(\"Missing values:\", df.isnull().sum())\n",
    "\n",
    "# What's wrong with each line? How would you fix it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-3-3-response",
   "metadata": {},
   "source": [
    "*Bugs identified:*\n",
    "\n",
    "1. Bug 1: \n",
    "2. Bug 2: \n",
    "3. Bug 3: \n",
    "4. Bug 4: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-04",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 04: Feature Engineering\n",
    "\n",
    "## Exercise 4.1: Discussion - Domain Knowledge Features\n",
    "\n",
    "**Type:** :speech_balloon: Discussion (7 min)\n",
    "\n",
    "You're building a model to predict reaction yield. You have:\n",
    "- Temperature (K)\n",
    "- Pressure (atm)\n",
    "- Reactant concentrations (mol/L)\n",
    "- Catalyst loading (wt%)\n",
    "- Residence time (min)\n",
    "\n",
    "**Task:** With 2-3 neighbors, brainstorm engineered features that might improve predictions. Think about:\n",
    "- Physical/chemical relationships (Arrhenius, ideal gas law, etc.)\n",
    "- Ratios and interactions\n",
    "- Domain-specific transformations\n",
    "\n",
    "List at least 5 potential engineered features with brief justifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-4-1-response",
   "metadata": {},
   "source": [
    "*Engineered features:*\n",
    "\n",
    "| Feature | Formula/Description | Justification |\n",
    "|---------|--------------------|--------------|\n",
    "| 1. | | |\n",
    "| 2. | | |\n",
    "| 3. | | |\n",
    "| 4. | | |\n",
    "| 5. | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-4-2",
   "metadata": {},
   "source": [
    "## Exercise 4.2: Mini-Exercise - Scaling Matters\n",
    "\n",
    "**Type:** :wrench: Mini-Exercise (6 min)\n",
    "\n",
    "Demonstrate why feature scaling matters for distance-based algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-4-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Two data points with different feature scales\n",
    "# Point A: Temperature=400K, Pressure=5atm\n",
    "# Point B: Temperature=401K, Pressure=6atm\n",
    "\n",
    "A = np.array([400, 5])\n",
    "B = np.array([401, 6])\n",
    "\n",
    "# Task 1: Calculate Euclidean distance without scaling\n",
    "# dist_unscaled = ???\n",
    "\n",
    "# Task 2: Now consider that temperature range is 300-500K, pressure range is 1-10 atm\n",
    "# Scale both points and calculate distance again\n",
    "# (Hint: what's the relative change in each feature?)\n",
    "\n",
    "# Task 3: Which distance is more \"fair\"? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-4-3",
   "metadata": {},
   "source": [
    "## Exercise 4.3: Reflection - Feature Engineering Philosophy\n",
    "\n",
    "**Type:** :thinking: Reflection (3 min)\n",
    "\n",
    "\"Feature engineering is where domain expertise meets machine learning.\"\n",
    "\n",
    "Reflect on:\n",
    "1. Why might a chemical engineer create better features than a generic data scientist?\n",
    "2. Can we automate feature engineering? What are the limits?\n",
    "3. When might *too many* features be a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-4-3-response",
   "metadata": {},
   "source": [
    "*Your reflection:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-05",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 05: Dimensionality Reduction\n",
    "\n",
    "## Exercise 5.1: Prediction - Variance Explained\n",
    "\n",
    "**Type:** :crystal_ball: Prediction (3 min)\n",
    "\n",
    "You have a dataset with 10 features describing chemical compounds. You apply PCA.\n",
    "\n",
    "**Predict:** How much variance do you think PC1 will explain?\n",
    "\n",
    "- [ ] < 20% (features are independent)\n",
    "- [ ] 20-40% (some correlation)\n",
    "- [ ] 40-60% (moderate correlation)\n",
    "- [ ] > 60% (highly correlated features)\n",
    "\n",
    "**Consider:** What does your answer imply about the \"true\" dimensionality of the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-5-1-response",
   "metadata": {},
   "source": [
    "*Your prediction and reasoning:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-5-2",
   "metadata": {},
   "source": [
    "## Exercise 5.2: Mini-Exercise - Interpret PCA Loadings\n",
    "\n",
    "**Type:** :wrench: Mini-Exercise (7 min)\n",
    "\n",
    "Analyze PCA loadings to understand what each component represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-5-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Polymer property data (synthetic)\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "\n",
    "# Create correlated features\n",
    "strength = np.random.normal(50, 10, n)\n",
    "hardness = strength * 0.8 + np.random.normal(0, 5, n)  # Correlated with strength\n",
    "flexibility = 100 - strength + np.random.normal(0, 8, n)  # Anti-correlated\n",
    "density = np.random.normal(1.2, 0.2, n)  # Independent\n",
    "cost = np.random.normal(10, 3, n)  # Independent\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'strength': strength,\n",
    "    'hardness': hardness,\n",
    "    'flexibility': flexibility,\n",
    "    'density': density,\n",
    "    'cost': cost\n",
    "})\n",
    "\n",
    "# Apply PCA\n",
    "X_scaled = StandardScaler().fit_transform(df)\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Look at loadings\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=[f'PC{i+1}' for i in range(5)],\n",
    "    index=df.columns\n",
    ")\n",
    "print(\"PCA Loadings:\")\n",
    "print(loadings.round(3))\n",
    "\n",
    "print(\"\\nVariance explained:\", pca.explained_variance_ratio_.round(3))\n",
    "\n",
    "# TASK: Interpret what PC1 and PC2 represent based on the loadings\n",
    "# What physical meaning can you assign to each component?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-5-2-response",
   "metadata": {},
   "source": [
    "*Your interpretation:*\n",
    "\n",
    "- PC1 represents:\n",
    "- PC2 represents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-5-3",
   "metadata": {},
   "source": [
    "## Exercise 5.3: Discussion - PCA vs t-SNE\n",
    "\n",
    "**Type:** :speech_balloon: Discussion (5 min)\n",
    "\n",
    "You need to visualize a high-dimensional dataset. When would you choose:\n",
    "\n",
    "1. **PCA** over t-SNE?\n",
    "2. **t-SNE** over PCA?\n",
    "3. **Both** (for different purposes)?\n",
    "\n",
    "Consider: interpretability, reproducibility, global vs local structure, computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-5-3-response",
   "metadata": {},
   "source": [
    "*Discussion notes:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-06",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 06: Linear Regression\n",
    "\n",
    "## Exercise 6.1: Critique - Coefficient Interpretation\n",
    "\n",
    "**Type:** :mag: Critique (5 min)\n",
    "\n",
    "A colleague shows you their regression model and says: \"Temperature has a coefficient of 0.002, and pressure has a coefficient of 5.3. Clearly pressure is way more important!\"\n",
    "\n",
    "**Task:** Write 2-3 sentences explaining why this interpretation might be wrong and what they should do instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-6-1-response",
   "metadata": {},
   "source": [
    "*Your critique:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-6-2",
   "metadata": {},
   "source": [
    "## Exercise 6.2: Mini-Exercise - Diagnose the Model\n",
    "\n",
    "**Type:** :wrench: Mini-Exercise (7 min)\n",
    "\n",
    "Look at these residual plots and diagnose what's wrong with each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-6-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "y_pred = np.linspace(0, 100, n)\n",
    "\n",
    "# Three different residual patterns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Pattern A: Curved residuals\n",
    "residuals_A = (y_pred - 50)**2 / 100 + np.random.normal(0, 2, n)\n",
    "axes[0].scatter(y_pred, residuals_A, alpha=0.6)\n",
    "axes[0].axhline(0, color='r', linestyle='--')\n",
    "axes[0].set_title('Model A')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Residual')\n",
    "\n",
    "# Pattern B: Fan shape\n",
    "residuals_B = np.random.normal(0, y_pred/10 + 0.5, n)\n",
    "axes[1].scatter(y_pred, residuals_B, alpha=0.6)\n",
    "axes[1].axhline(0, color='r', linestyle='--')\n",
    "axes[1].set_title('Model B')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "\n",
    "# Pattern C: Good residuals\n",
    "residuals_C = np.random.normal(0, 3, n)\n",
    "axes[2].scatter(y_pred, residuals_C, alpha=0.6)\n",
    "axes[2].axhline(0, color='r', linestyle='--')\n",
    "axes[2].set_title('Model C')\n",
    "axes[2].set_xlabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TASK: For each model, identify:\n",
    "# 1. What pattern do you see?\n",
    "# 2. What does it indicate?\n",
    "# 3. How would you fix it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-6-2-response",
   "metadata": {},
   "source": [
    "*Your diagnosis:*\n",
    "\n",
    "**Model A:**\n",
    "- Pattern:\n",
    "- Problem:\n",
    "- Fix:\n",
    "\n",
    "**Model B:**\n",
    "- Pattern:\n",
    "- Problem:\n",
    "- Fix:\n",
    "\n",
    "**Model C:**\n",
    "- Pattern:\n",
    "- Problem:\n",
    "- Fix:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-6-3",
   "metadata": {},
   "source": [
    "## Exercise 6.3: Reflection - Causation vs Correlation\n",
    "\n",
    "**Type:** :thinking: Reflection (3 min)\n",
    "\n",
    "Your regression model shows that \"catalyst age\" has a negative coefficient for yield. A manager suggests: \"Let's always use fresh catalyst!\"\n",
    "\n",
    "**Reflect:**\n",
    "1. Does the coefficient prove that old catalyst *causes* lower yields?\n",
    "2. What else might explain the relationship?\n",
    "3. What would you need to establish causation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-6-3-response",
   "metadata": {},
   "source": [
    "*Your reflection:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-07",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 07: Classification\n",
    "\n",
    "## Exercise 7.1: Discussion - Choosing Metrics\n",
    "\n",
    "**Type:** :speech_balloon: Discussion (5 min)\n",
    "\n",
    "You're building a classifier to detect faulty batches in a chemical plant. Only 2% of batches are faulty.\n",
    "\n",
    "**Discuss with a partner:**\n",
    "1. If you predict \"good\" for every batch, what's your accuracy?\n",
    "2. Why is accuracy a bad metric here?\n",
    "3. Which metric would you use instead: precision, recall, or F1? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-7-1-response",
   "metadata": {},
   "source": [
    "*Discussion notes:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-7-2",
   "metadata": {},
   "source": [
    "## Exercise 7.2: Mini-Exercise - Confusion Matrix Interpretation\n",
    "\n",
    "**Type:** :wrench: Mini-Exercise (6 min)\n",
    "\n",
    "Calculate metrics from a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-7-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A classifier for detecting equipment failures\n",
    "# Confusion matrix:\n",
    "#                 Predicted\n",
    "#              | Normal | Failure |\n",
    "# Actual Normal |   85   |   10    |\n",
    "# Actual Failure|    3   |    2    |\n",
    "\n",
    "# True Positives (TP) = correctly predicted failures = 2\n",
    "# True Negatives (TN) = correctly predicted normal = 85\n",
    "# False Positives (FP) = normal predicted as failure = 10\n",
    "# False Negatives (FN) = failure predicted as normal = 3\n",
    "\n",
    "TP, TN, FP, FN = 2, 85, 10, 3\n",
    "\n",
    "# TASK: Calculate these metrics\n",
    "# accuracy = ???\n",
    "# precision = ???  (of predicted failures, how many were real?)\n",
    "# recall = ???  (of actual failures, how many did we catch?)\n",
    "# f1 = ???\n",
    "\n",
    "# Which metric is most concerning? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-7-2-response",
   "metadata": {},
   "source": [
    "*Your calculations and interpretation:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-7-3",
   "metadata": {},
   "source": [
    "## Exercise 7.3: Prediction - ROC Curves\n",
    "\n",
    "**Type:** :crystal_ball: Prediction (3 min)\n",
    "\n",
    "You have two classifiers:\n",
    "- **Model A**: High precision (0.9), low recall (0.3)\n",
    "- **Model B**: Low precision (0.5), high recall (0.9)\n",
    "\n",
    "**Predict:** Sketch (mentally or on paper) where each model's operating point would be on an ROC curve. Which model has higher AUC?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-7-3-response",
   "metadata": {},
   "source": [
    "*Your prediction:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-08",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 08: Regularization & Model Selection\n",
    "\n",
    "## Exercise 8.1: Discussion - The Bias-Variance Tradeoff\n",
    "\n",
    "**Type:** :speech_balloon: Discussion (5 min)\n",
    "\n",
    "Explain the bias-variance tradeoff to a partner as if they've never heard of it:\n",
    "\n",
    "1. What is bias? What is variance?\n",
    "2. Why can't we minimize both at the same time?\n",
    "3. Give a real-world analogy (not from machine learning)\n",
    "\n",
    "**Challenge:** Can you explain it in under 30 seconds?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-8-1-response",
   "metadata": {},
   "source": [
    "*Your explanation:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-8-2",
   "metadata": {},
   "source": [
    "## Exercise 8.2: Mini-Exercise - Ridge vs Lasso\n",
    "\n",
    "**Type:** :wrench: Mini-Exercise (7 min)\n",
    "\n",
    "Observe how Ridge and Lasso affect coefficients differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-8-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create data with some useless features\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "X = np.random.randn(n, 5)\n",
    "# Only first 2 features matter, rest are noise\n",
    "y = 3*X[:, 0] + 2*X[:, 1] + np.random.randn(n)*0.5\n",
    "\n",
    "feature_names = ['important_1', 'important_2', 'noise_1', 'noise_2', 'noise_3']\n",
    "\n",
    "# Scale features\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Fit models with different regularization\n",
    "models = {\n",
    "    'OLS': LinearRegression(),\n",
    "    'Ridge (alpha=1)': Ridge(alpha=1),\n",
    "    'Lasso (alpha=0.1)': Lasso(alpha=0.1)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_scaled, y)\n",
    "    results[name] = model.coef_\n",
    "\n",
    "coef_df = pd.DataFrame(results, index=feature_names)\n",
    "print(\"Coefficients:\")\n",
    "print(coef_df.round(3))\n",
    "\n",
    "# TASK: \n",
    "# 1. Which model correctly identifies the noise features?\n",
    "# 2. When would you prefer Ridge over Lasso?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-8-2-response",
   "metadata": {},
   "source": [
    "*Your observations:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-8-3",
   "metadata": {},
   "source": [
    "## Exercise 8.3: Critique - Cross-Validation Mistakes\n",
    "\n",
    "**Type:** :mag: Critique (5 min)\n",
    "\n",
    "Find the data leakage in this cross-validation workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-8-3-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# BUGGY cross-validation workflow\n",
    "# X, y = load_data()\n",
    "\n",
    "# Step 1: Scale all data\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)  # <-- PROBLEM HERE!\n",
    "\n",
    "# Step 2: Cross-validate\n",
    "# scores = cross_val_score(Ridge(), X_scaled, y, cv=5)\n",
    "\n",
    "# TASK: What's wrong with this workflow?\n",
    "# How should it be done correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-8-3-response",
   "metadata": {},
   "source": [
    "*The problem:*\n",
    "\n",
    "*The fix:*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-09",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 09: Nonlinear Methods\n",
    "\n",
    "## Exercise 9.1: Prediction - Method Selection\n",
    "\n",
    "**Type:** :crystal_ball: Prediction (3 min)\n",
    "\n",
    "For each scenario, predict which method would work best: **Linear Regression**, **Polynomial Regression**, **Decision Tree**, or **k-Nearest Neighbors**.\n",
    "\n",
    "| Scenario | Your Choice | Reasoning |\n",
    "|----------|-------------|----------|\n",
    "| Predicting yield from temperature (Arrhenius-like) | | |\n",
    "| Classifying materials into 5 categories based on properties | | |\n",
    "| Predicting property with many step-changes/thresholds | | |\n",
    "| Predicting output from 100 features, most are noise | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-9-1-response",
   "metadata": {},
   "source": [
    "*Fill in the table above*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-9-2",
   "metadata": {},
   "source": [
    "## Exercise 9.2: Mini-Exercise - Overfitting Visualization\n",
    "\n",
    "**Type:** :wrench: Mini-Exercise (7 min)\n",
    "\n",
    "Visualize overfitting with polynomial regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-9-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Generate noisy data from a simple quadratic\n",
    "np.random.seed(42)\n",
    "X = np.linspace(0, 1, 15).reshape(-1, 1)\n",
    "y = 2*X.ravel()**2 - X.ravel() + 0.5 + np.random.randn(15)*0.1\n",
    "\n",
    "X_plot = np.linspace(-0.1, 1.1, 100).reshape(-1, 1)\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# TASK: Try degrees 1, 2, and 15\n",
    "# For each, plot the fit and observe what happens\n",
    "for i, degree in enumerate([1, 2, 15]):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    \n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    plt.scatter(X, y, color='blue', label='Data')\n",
    "    plt.plot(X_plot, model.predict(X_plot), color='red', label=f'Degree {degree}')\n",
    "    plt.ylim(-0.5, 2)\n",
    "    plt.title(f'Degree {degree}')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# QUESTION: Which degree is best? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-9-2-response",
   "metadata": {},
   "source": [
    "*Your observation:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-9-3",
   "metadata": {},
   "source": [
    "## Exercise 9.3: Discussion - Interpretability vs Performance\n",
    "\n",
    "**Type:** :speech_balloon: Discussion (5 min)\n",
    "\n",
    "You're presenting model results to plant operators who need to understand *why* the model makes certain predictions.\n",
    "\n",
    "**Discuss:**\n",
    "1. Rank these models from most to least interpretable: Linear Regression, Random Forest, Neural Network, Decision Tree\n",
    "2. When might you sacrifice interpretability for performance?\n",
    "3. How could you make a black-box model more interpretable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-9-3-response",
   "metadata": {},
   "source": [
    "*Discussion notes:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 10: Ensemble Methods\n",
    "\n",
    "## Exercise 10.1: Discussion - Wisdom of Crowds\n",
    "\n",
    "**Type:** :speech_balloon: Discussion (5 min)\n",
    "\n",
    "The \"wisdom of crowds\" says that averaging many independent estimates is often more accurate than any single expert.\n",
    "\n",
    "**Discuss:**\n",
    "1. How does this relate to ensemble methods in ML?\n",
    "2. What's the key word in \"independent estimates\"? Why does it matter?\n",
    "3. How do Random Forests achieve independence between trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-10-1-response",
   "metadata": {},
   "source": [
    "*Discussion notes:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-10-2",
   "metadata": {},
   "source": [
    "## Exercise 10.2: Mini-Exercise - Feature Importance\n",
    "\n",
    "**Type:** :wrench: Mini-Exercise (7 min)\n",
    "\n",
    "Compare feature importance from Random Forest vs coefficients from Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-10-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create data with a nonlinear relationship\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "\n",
    "X1 = np.random.uniform(0, 10, n)  # Important, nonlinear effect\n",
    "X2 = np.random.uniform(0, 10, n)  # Important, linear effect\n",
    "X3 = np.random.uniform(0, 10, n)  # Noise\n",
    "\n",
    "# y has nonlinear dependence on X1, linear on X2\n",
    "y = np.sin(X1) + 0.5*X2 + np.random.randn(n)*0.3\n",
    "\n",
    "X = np.column_stack([X1, X2, X3])\n",
    "feature_names = ['nonlinear_feature', 'linear_feature', 'noise']\n",
    "\n",
    "# Fit both models\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(StandardScaler().fit_transform(X), y)\n",
    "\n",
    "print(\"Random Forest Feature Importance:\")\n",
    "for name, imp in zip(feature_names, rf.feature_importances_):\n",
    "    print(f\"  {name}: {imp:.3f}\")\n",
    "\n",
    "print(\"\\nLinear Regression Coefficients (standardized):\")\n",
    "for name, coef in zip(feature_names, np.abs(lr.coef_)):\n",
    "    print(f\"  {name}: {coef:.3f}\")\n",
    "\n",
    "# TASK: Why do the rankings differ?\n",
    "# Which method gives a more accurate picture of importance here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-10-2-response",
   "metadata": {},
   "source": [
    "*Your analysis:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-10-3",
   "metadata": {},
   "source": [
    "## Exercise 10.3: Reflection - When to Use Ensembles\n",
    "\n",
    "**Type:** :thinking: Reflection (3 min)\n",
    "\n",
    "Ensemble methods often win ML competitions. But they're not always the right choice.\n",
    "\n",
    "**Reflect on scenarios where you might NOT use an ensemble:**\n",
    "- When interpretability is critical?\n",
    "- When computational resources are limited?\n",
    "- When you need fast predictions in real-time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-10-3-response",
   "metadata": {},
   "source": [
    "*Your reflection:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 11: Clustering\n",
    "\n",
    "## Exercise 11.1: Prediction - How Many Clusters?\n",
    "\n",
    "**Type:** :crystal_ball: Prediction (3 min)\n",
    "\n",
    "You have process data from a reactor that operates in three known modes: startup, steady-state, and shutdown. You apply k-means.\n",
    "\n",
    "**Predict:** Will k-means with k=3 find clusters that match the three operating modes?\n",
    "\n",
    "- [ ] Yes, definitely\n",
    "- [ ] Probably, if the modes are well-separated\n",
    "- [ ] Probably not, clusters aren't always meaningful\n",
    "- [ ] No, k-means can't find interpretable clusters\n",
    "\n",
    "**Explain your reasoning.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-11-1-response",
   "metadata": {},
   "source": [
    "*Your prediction and reasoning:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-11-2",
   "metadata": {},
   "source": [
    "## Exercise 11.2: Mini-Exercise - Scaling Impact\n",
    "\n",
    "**Type:** :wrench: Mini-Exercise (6 min)\n",
    "\n",
    "See how scaling affects k-means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-11-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Two features with very different scales\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "\n",
    "# Temperature (300-500 K) and pressure (1-10 atm)\n",
    "# Two natural clusters based on pressure\n",
    "cluster1 = np.column_stack([\n",
    "    np.random.normal(400, 30, n//2),  # temperature\n",
    "    np.random.normal(3, 0.5, n//2)    # pressure\n",
    "])\n",
    "cluster2 = np.column_stack([\n",
    "    np.random.normal(400, 30, n//2),  # temperature\n",
    "    np.random.normal(7, 0.5, n//2)    # pressure\n",
    "])\n",
    "X = np.vstack([cluster1, cluster2])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Without scaling\n",
    "kmeans_unscaled = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "labels_unscaled = kmeans_unscaled.fit_predict(X)\n",
    "axes[0].scatter(X[:, 0], X[:, 1], c=labels_unscaled, cmap='viridis')\n",
    "axes[0].set_xlabel('Temperature (K)')\n",
    "axes[0].set_ylabel('Pressure (atm)')\n",
    "axes[0].set_title('K-means WITHOUT scaling')\n",
    "\n",
    "# With scaling\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "kmeans_scaled = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "labels_scaled = kmeans_scaled.fit_predict(X_scaled)\n",
    "axes[1].scatter(X[:, 0], X[:, 1], c=labels_scaled, cmap='viridis')\n",
    "axes[1].set_xlabel('Temperature (K)')\n",
    "axes[1].set_ylabel('Pressure (atm)')\n",
    "axes[1].set_title('K-means WITH scaling')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TASK: Explain the difference. Which clustering is \"correct\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-11-2-response",
   "metadata": {},
   "source": [
    "*Your explanation:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-11-3",
   "metadata": {},
   "source": [
    "## Exercise 11.3: Discussion - Clustering Without Ground Truth\n",
    "\n",
    "**Type:** :speech_balloon: Discussion (5 min)\n",
    "\n",
    "Clustering is unsupervised - there are no labels to tell us if we're right.\n",
    "\n",
    "**Discuss:**\n",
    "1. How do you validate clusters without ground truth?\n",
    "2. When might silhouette score be misleading?\n",
    "3. What role does domain expertise play in evaluating clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-11-3-response",
   "metadata": {},
   "source": [
    "*Discussion notes:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 12: Uncertainty Quantification\n",
    "\n",
    "## Exercise 12.1: Reflection - Communicating Uncertainty\n",
    "\n",
    "**Type:** :thinking: Reflection (3 min)\n",
    "\n",
    "Your model predicts a reactor yield of 75% with a 95% confidence interval of [65%, 85%].\n",
    "\n",
    "**Reflect:**\n",
    "1. How would you explain this to a plant manager who asks \"So what's the yield going to be?\"\n",
    "2. Why might the manager find uncertainty uncomfortable?\n",
    "3. Why is communicating uncertainty important for decision-making?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-12-1-response",
   "metadata": {},
   "source": [
    "*Your reflection:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-12-2",
   "metadata": {},
   "source": [
    "## Exercise 12.2: Mini-Exercise - Bootstrap Confidence Intervals\n",
    "\n",
    "**Type:** :wrench: Mini-Exercise (8 min)\n",
    "\n",
    "Calculate a bootstrap confidence interval for a regression coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-12-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Simple linear data\n",
    "np.random.seed(42)\n",
    "n = 50\n",
    "X = np.random.uniform(0, 10, n).reshape(-1, 1)\n",
    "y = 2.5 * X.ravel() + 5 + np.random.randn(n) * 2  # True slope = 2.5\n",
    "\n",
    "# Single model fit\n",
    "model = LinearRegression().fit(X, y)\n",
    "print(f\"Point estimate for slope: {model.coef_[0]:.3f}\")\n",
    "\n",
    "# TASK: Implement bootstrap to get confidence interval\n",
    "n_bootstrap = 1000\n",
    "bootstrap_slopes = []\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    # 1. Sample with replacement from the data\n",
    "    # indices = ???\n",
    "    \n",
    "    # 2. Fit model on bootstrap sample\n",
    "    # X_boot = ???\n",
    "    # y_boot = ???\n",
    "    # model_boot = ???\n",
    "    \n",
    "    # 3. Store the coefficient\n",
    "    # bootstrap_slopes.append(???)\n",
    "    pass\n",
    "\n",
    "# 4. Calculate 95% CI\n",
    "# ci_lower = np.percentile(bootstrap_slopes, ???)\n",
    "# ci_upper = np.percentile(bootstrap_slopes, ???)\n",
    "# print(f\"95% CI for slope: [{ci_lower:.3f}, {ci_upper:.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-12-3",
   "metadata": {},
   "source": [
    "## Exercise 12.3: Discussion - Sources of Uncertainty\n",
    "\n",
    "**Type:** :speech_balloon: Discussion (5 min)\n",
    "\n",
    "A machine learning model has multiple sources of uncertainty.\n",
    "\n",
    "**Categorize these sources as \"aleatory\" (irreducible) or \"epistemic\" (reducible):**\n",
    "\n",
    "1. Measurement noise in sensors\n",
    "2. Model doesn't include an important variable\n",
    "3. Inherent randomness in a chemical process\n",
    "4. Not enough training data\n",
    "5. Wrong model architecture\n",
    "\n",
    "**Which can we reduce by collecting more data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-12-3-response",
   "metadata": {},
   "source": [
    "*Classification:*\n",
    "\n",
    "| Source | Aleatory or Epistemic? | Can more data help? |\n",
    "|--------|----------------------|--------------------|\n",
    "| 1. Measurement noise | | |\n",
    "| 2. Missing variable | | |\n",
    "| 3. Process randomness | | |\n",
    "| 4. Limited training data | | |\n",
    "| 5. Wrong architecture | | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "module-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Module 13: Model Interpretability\n",
    "\n",
    "## Exercise 13.1: Discussion - Explaining to Stakeholders\n",
    "\n",
    "**Type:** :speech_balloon: Discussion (5 min)\n",
    "\n",
    "Your black-box model recommends changing a reactor setpoint. The operator asks: \"Why?\"\n",
    "\n",
    "**Discuss:**\n",
    "1. What would be a satisfying answer?\n",
    "2. How might SHAP values help?\n",
    "3. When might \"trust the model\" be an acceptable answer? When is it not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-13-1-response",
   "metadata": {},
   "source": [
    "*Discussion notes:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-13-2",
   "metadata": {},
   "source": [
    "## Exercise 13.2: Mini-Exercise - SHAP Interpretation\n",
    "\n",
    "**Type:** :wrench: Mini-Exercise (7 min)\n",
    "\n",
    "Interpret a SHAP summary plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ex-13-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create interpretable data\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "\n",
    "temperature = np.random.uniform(300, 500, n)\n",
    "pressure = np.random.uniform(1, 10, n)\n",
    "catalyst = np.random.uniform(1, 5, n)\n",
    "\n",
    "# yield increases with temp and pressure, decreases with too much catalyst\n",
    "y = (0.1 * temperature + \n",
    "     5 * pressure + \n",
    "     10 * catalyst - catalyst**2 +  # Optimum catalyst loading\n",
    "     np.random.randn(n) * 3)\n",
    "\n",
    "X = np.column_stack([temperature, pressure, catalyst])\n",
    "feature_names = ['temperature', 'pressure', 'catalyst_loading']\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# If SHAP is available:\n",
    "try:\n",
    "    import shap\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X[:50])  # Sample for speed\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values, X[:50], feature_names=feature_names, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"SHAP not available - interpret feature importance instead:\")\n",
    "    for name, imp in zip(feature_names, model.feature_importances_):\n",
    "        print(f\"  {name}: {imp:.3f}\")\n",
    "\n",
    "# TASK: Based on the plot (or importances):\n",
    "# 1. Which feature has the largest impact?\n",
    "# 2. Is the effect of temperature positive or negative?\n",
    "# 3. What's unusual about catalyst_loading?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-13-2-response",
   "metadata": {},
   "source": [
    "*Your interpretation:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-13-3",
   "metadata": {},
   "source": [
    "## Exercise 13.3: Reflection - The Right to Explanation\n",
    "\n",
    "**Type:** :thinking: Reflection (3 min)\n",
    "\n",
    "In many contexts (medical, legal, financial), there's growing demand for \"explainable AI.\"\n",
    "\n",
    "**Reflect:**\n",
    "1. In chemical engineering applications, when is model explainability critical?\n",
    "2. When might an unexplainable model be acceptable?\n",
    "3. How does interpretability relate to trust and safety?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ex-13-3-response",
   "metadata": {},
   "source": [
    "*Your reflection:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# End-of-Course Reflection\n",
    "\n",
    "## Final Reflection: Your Data Science Journey\n",
    "\n",
    "**Type:** :thinking: Reflection (5 min)\n",
    "\n",
    "1. **Most surprising thing you learned:**\n",
    "\n",
    "2. **Concept you found most challenging:**\n",
    "\n",
    "3. **How you plan to use these skills:**\n",
    "\n",
    "4. **One question you still have:**\n",
    "\n",
    "5. **Advice you'd give to future students:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-response",
   "metadata": {},
   "source": [
    "*Your final reflection:*\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
