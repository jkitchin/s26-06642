{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jkitchin/s26-06642/blob/main/dsmles/12-uncertainty-quantification/uncertainty-quantification.ipynb)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "! pip install -q pycse\nfrom pycse.colab import pdf",
   "metadata": {
    "tags": [
     "skip-execution",
     "remove-cell"
    ]
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 10: Uncertainty Quantification\n",
    "\n",
    "Quantifying confidence in model predictions.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Understand why uncertainty matters in engineering\n",
    "2. Use pycse for regression with confidence intervals\n",
    "3. Apply nonlinear fitting with uncertainty\n",
    "4. Use Gaussian Processes for probabilistic predictions\n",
    "5. Propagate uncertainty through calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel\n",
    "\n",
    "# pycse for uncertainty quantification\n",
    "from pycse import regress, nlinfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Why Uncertainty Matters: The Engineering Imperative\n\nIn science, we publish point estimates. In engineering, we design with safety margins. The difference is **uncertainty**.\n\n### Real-World Consequences\n\n| Scenario | What You Predict | What You Need to Know |\n|----------|------------------|----------------------|\n| Reactor design | Optimal temperature: 450 K | Is it 450 \u00b1 5 K or 450 \u00b1 50 K? |\n| Material strength | Mean strength: 100 MPa | What's the 1% failure threshold? |\n| Process optimization | Expected yield: 85% | What's the range we'll actually see? |\n| Economic analysis | Predicted cost: $1M | Could it be $2M? $500K? |\n\n### Types of Uncertainty\n\n1. **Measurement uncertainty**: Sensor noise, calibration errors\n2. **Model uncertainty**: Model is an approximation of reality\n3. **Parameter uncertainty**: Fitted parameters have error\n4. **Extrapolation uncertainty**: Predictions outside training range\n\n### The Honest Scientist's Burden\n\n**A prediction without uncertainty is incomplete.** When you report \"conversion = 75%,\" you're implicitly claiming infinite precision. Better: \"conversion = 75 \u00b1 5%\"\n\nThis module teaches you how to quantify and propagate uncertainty\u2014essential skills for engineering practice."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Linear Regression with pycse: Parameters + Confidence\n\nThe `pycse` library (Python for Computational Science and Engineering) makes uncertainty quantification easy. The `regress` function returns not just fitted parameters, but their confidence intervals.\n\n### Why This Matters\n\nStandard scikit-learn gives you coefficients but not their uncertainties. For engineering decisions, you need to know:\n- Is this coefficient significantly different from zero?\n- How precise is our estimate?\n- What's the range of predictions we should expect?\n\n### The Output Format\n\n`regress(X, y)` returns:\n- `p`: Parameter estimates\n- `pint`: 95% confidence intervals for each parameter\n- `se`: Standard errors"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experimental data: reaction rate vs temperature\n",
    "np.random.seed(42)\n",
    "\n",
    "# Arrhenius-like data (linearized): ln(k) = ln(A) - Ea/(R*T)\n",
    "T = np.array([300, 320, 340, 360, 380, 400, 420, 440])  # Temperature (K)\n",
    "R = 8.314  # Gas constant (J/mol/K)\n",
    "\n",
    "# True parameters\n",
    "Ea_true = 50000  # Activation energy (J/mol)\n",
    "A_true = 1e8     # Pre-exponential factor\n",
    "\n",
    "# Generate noisy data\n",
    "ln_k_true = np.log(A_true) - Ea_true / (R * T)\n",
    "ln_k = ln_k_true + np.random.normal(0, 0.3, len(T))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(1/T * 1000, ln_k, s=80, label='Experimental data')\n",
    "plt.xlabel('1000/T (1/K)')\n",
    "plt.ylabel('ln(k)')\n",
    "plt.title('Arrhenius Plot')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with pycse.regress\n",
    "# Model: ln(k) = b0 + b1 * (1/T)\n",
    "# where b0 = ln(A) and b1 = -Ea/R\n",
    "\n",
    "X = np.column_stack([np.ones(len(T)), 1/T])\n",
    "y = ln_k\n",
    "\n",
    "# regress returns: parameters, confidence intervals, predicted values\n",
    "p, pint, se = regress(X, y, alpha=0.05)\n",
    "\n",
    "print(\"Linear Regression Results (95% CI):\")\n",
    "print(f\"  ln(A) = {p[0]:.3f} \u00b1 {(pint[0,1]-pint[0,0])/2:.3f}\")\n",
    "print(f\"  -Ea/R = {p[1]:.1f} \u00b1 {(pint[1,1]-pint[1,0])/2:.1f}\")\n",
    "\n",
    "# Convert to physical parameters\n",
    "A_est = np.exp(p[0])\n",
    "Ea_est = -p[1] * R\n",
    "\n",
    "print(f\"\\nPhysical Parameters:\")\n",
    "print(f\"  A = {A_est:.2e} (true: {A_true:.2e})\")\n",
    "print(f\"  Ea = {Ea_est/1000:.1f} kJ/mol (true: {Ea_true/1000:.1f} kJ/mol)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "**What pycse gives us that scikit-learn doesn't:**\n\nThe `regress` function returns **confidence intervals** on the parameters, not just point estimates. This is crucial for engineering:\n\n- We know ln(A) = 18.5, but the 95% CI tells us it could reasonably be 18.2 to 18.8\n- We know Ea/R \u2248 6000 K, but the CI shows our uncertainty\n\n**Physical interpretation:**\n- The estimated activation energy Ea \u2248 50 kJ/mol matches our \"true\" value\n- The pre-exponential factor A \u2248 10\u2078 s\u207b\u00b9 is also recovered well\n- The narrow confidence intervals indicate precise parameter estimates (good data quality)\n\nThis is the difference between \"our activation energy is 50 kJ/mol\" (overconfident) and \"our activation energy is 50 \u00b1 3 kJ/mol at 95% confidence\" (honest science).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with confidence bands\n",
    "T_plot = np.linspace(290, 450, 100)\n",
    "X_plot = np.column_stack([np.ones(len(T_plot)), 1/T_plot])\n",
    "\n",
    "# Predicted values\n",
    "ln_k_pred = X_plot @ p\n",
    "\n",
    "# Confidence interval for predictions\n",
    "from scipy import stats\n",
    "n = len(T)\n",
    "dof = n - 2\n",
    "t_val = stats.t.ppf(0.975, dof)\n",
    "residuals = y - X @ p\n",
    "mse = np.sum(residuals**2) / dof\n",
    "\n",
    "# Standard error of prediction\n",
    "XtX_inv = np.linalg.inv(X.T @ X)\n",
    "se_pred = np.sqrt(mse * np.array([x @ XtX_inv @ x for x in X_plot]))\n",
    "ci = t_val * se_pred\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(1/T * 1000, ln_k, s=80, label='Data', zorder=5)\n",
    "plt.plot(1/T_plot * 1000, ln_k_pred, 'r-', linewidth=2, label='Fit')\n",
    "plt.fill_between(1/T_plot * 1000, ln_k_pred - ci, ln_k_pred + ci, \n",
    "                 alpha=0.3, color='red', label='95% CI')\n",
    "plt.xlabel('1000/T (1/K)')\n",
    "plt.ylabel('ln(k)')\n",
    "plt.title('Arrhenius Fit with Confidence Interval')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Fitting with pycse\n",
    "\n",
    "The `pycse.nlinfit` function handles nonlinear models with uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Michaelis-Menten kinetics: V = Vmax * S / (Km + S)\n",
    "np.random.seed(42)\n",
    "\n",
    "S = np.array([0.5, 1, 2, 4, 8, 16, 32, 64])  # Substrate concentration\n",
    "Vmax_true = 100\n",
    "Km_true = 5\n",
    "\n",
    "V_true = Vmax_true * S / (Km_true + S)\n",
    "V = V_true + np.random.normal(0, 3, len(S))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(S, V, s=80, label='Data')\n",
    "plt.xlabel('Substrate Concentration [S]')\n",
    "plt.ylabel('Reaction Rate V')\n",
    "plt.title('Michaelis-Menten Kinetics')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model function\n",
    "def michaelis_menten(S, Vmax, Km):\n",
    "    return Vmax * S / (Km + S)\n",
    "\n",
    "# Initial guesses\n",
    "p0 = [80, 3]\n",
    "\n",
    "# Nonlinear fit with pycse\n",
    "p, pint, se = nlinfit(michaelis_menten, S, V, p0, alpha=0.05)\n",
    "\n",
    "print(\"Nonlinear Regression Results (95% CI):\")\n",
    "print(f\"  Vmax = {p[0]:.2f} \u00b1 {(pint[0,1]-pint[0,0])/2:.2f} (true: {Vmax_true})\")\n",
    "print(f\"  Km = {p[1]:.2f} \u00b1 {(pint[1,1]-pint[1,0])/2:.2f} (true: {Km_true})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fit\n",
    "S_plot = np.linspace(0.1, 70, 200)\n",
    "V_fit = michaelis_menten(S_plot, *p)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(S, V, s=80, label='Data', zorder=5)\n",
    "plt.plot(S_plot, V_fit, 'r-', linewidth=2, label='Fit')\n",
    "plt.axhline(y=p[0], color='gray', linestyle='--', alpha=0.5, label=f'Vmax = {p[0]:.1f}')\n",
    "plt.axvline(x=p[1], color='gray', linestyle=':', alpha=0.5, label=f'Km = {p[1]:.1f}')\n",
    "plt.xlabel('Substrate Concentration [S]')\n",
    "plt.ylabel('Reaction Rate V')\n",
    "plt.title('Michaelis-Menten Fit')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Gaussian Process Regression: Uncertainty That Knows What It Doesn't Know\n\nGaussian Processes (GPs) are fundamentally different from other regression methods. They don't just give predictions\u2014they give **probability distributions** over predictions.\n\n### The Key Insight\n\nA GP knows where it has data and where it doesn't. Predictions close to training points are confident (small uncertainty). Predictions far from training points are uncertain (large uncertainty).\n\nThis is exactly what we want for engineering! If you're extrapolating, the model should tell you it's uncertain.\n\n### When to Use GPs\n\n| Situation | GP Advantage |\n|-----------|--------------|\n| Expensive experiments | Guides where to sample next |\n| Optimization | Balances exploration vs exploitation |\n| Sparse data | Interpolates smoothly with uncertainty |\n| Critical predictions | Honest about what it doesn't know |\n\n### The Tradeoff\n\nGPs are powerful but:\n- Scale poorly to large datasets (O(n\u00b3) training)\n- Require kernel selection (domain knowledge helps)\n- Can underestimate uncertainty far from training data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data\n",
    "np.random.seed(42)\n",
    "\n",
    "X_train = np.array([1, 2, 3, 5, 6, 8]).reshape(-1, 1)\n",
    "y_train = np.sin(X_train).ravel() + np.random.normal(0, 0.1, len(X_train))\n",
    "\n",
    "# Define kernel\n",
    "kernel = ConstantKernel(1.0) * RBF(length_scale=1.0) + WhiteKernel(noise_level=0.1)\n",
    "\n",
    "# Fit GP\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
    "gp.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Optimized kernel: {gp.kernel_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "**Notice the key feature of Gaussian Processes:**\n\n1. **Near training data (x=1-8)**: The uncertainty band is narrow. The GP is confident because it has data here.\n\n2. **Far from training data (x=0-1, x=8-10)**: The uncertainty band widens dramatically. The GP is honest about what it doesn't know.\n\n3. **Between training points**: Uncertainty is intermediate\u2014reasonable interpolation.\n\n**Compare to standard regression**: A linear or polynomial model would give the same confidence interval everywhere. It doesn't \"know\" that x=9 is far from training data while x=5 is close to training points.\n\n**The GP's uncertainty is data-aware.** This is exactly what we want for engineering applications:\n- Confident predictions where we have experimental support\n- Honest uncertainty where we're extrapolating\n- Guidance on where to collect more data (the uncertain regions!)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with uncertainty\n",
    "X_test = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y_pred, y_std = gp.predict(X_test, return_std=True)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot predictions with uncertainty\n",
    "plt.plot(X_test, y_pred, 'b-', linewidth=2, label='GP Mean')\n",
    "plt.fill_between(X_test.ravel(), \n",
    "                 y_pred - 1.96*y_std, \n",
    "                 y_pred + 1.96*y_std, \n",
    "                 alpha=0.3, color='blue', label='95% CI')\n",
    "plt.fill_between(X_test.ravel(), \n",
    "                 y_pred - y_std, \n",
    "                 y_pred + y_std, \n",
    "                 alpha=0.3, color='blue')\n",
    "\n",
    "# Plot training data\n",
    "plt.scatter(X_train, y_train, c='red', s=100, zorder=5, label='Training data')\n",
    "\n",
    "# Plot true function\n",
    "plt.plot(X_test, np.sin(X_test), 'k--', alpha=0.5, label='True function')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Gaussian Process Regression with Uncertainty')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP for chemical engineering: Catalyst activity prediction\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sparse training data\n",
    "temp_train = np.array([300, 350, 400, 500, 550]).reshape(-1, 1)\n",
    "activity_train = np.array([10, 35, 75, 95, 85])  # Activity peaks, then decreases (sintering)\n",
    "\n",
    "# Fit GP\n",
    "kernel = ConstantKernel(100) * RBF(length_scale=50) + WhiteKernel(noise_level=5)\n",
    "gp_cat = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
    "gp_cat.fit(temp_train, activity_train)\n",
    "\n",
    "# Predict\n",
    "temp_test = np.linspace(280, 600, 100).reshape(-1, 1)\n",
    "activity_pred, activity_std = gp_cat.predict(temp_test, return_std=True)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(temp_test, activity_pred, 'b-', linewidth=2, label='GP Prediction')\n",
    "plt.fill_between(temp_test.ravel(), \n",
    "                 activity_pred - 1.96*activity_std, \n",
    "                 activity_pred + 1.96*activity_std, \n",
    "                 alpha=0.3, color='blue', label='95% CI')\n",
    "plt.scatter(temp_train, activity_train, c='red', s=100, zorder=5, label='Experiments')\n",
    "\n",
    "plt.xlabel('Temperature (K)')\n",
    "plt.ylabel('Catalyst Activity')\n",
    "plt.title('Catalyst Activity Prediction with Uncertainty')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Find optimal temperature\n",
    "opt_idx = np.argmax(activity_pred)\n",
    "print(f\"\\nOptimal temperature: {temp_test[opt_idx, 0]:.0f} K\")\n",
    "print(f\"Expected activity: {activity_pred[opt_idx]:.1f} \u00b1 {1.96*activity_std[opt_idx]:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Uncertainty Propagation: How Errors Compound\n\nWhen inputs have uncertainty, outputs have uncertainty too. But how much?\n\n### Two Approaches\n\n| Method | How It Works | When to Use |\n|--------|--------------|-------------|\n| **Analytical** | Taylor expansion, linear approximation | Simple functions, small uncertainties |\n| **Monte Carlo** | Sample inputs, compute outputs, analyze distribution | Complex functions, any uncertainty size |\n\n### The uncertainties Package\n\nFor analytical propagation, the `uncertainties` package is elegant. Define uncertain numbers, and it automatically tracks how uncertainty flows through calculations.\n\n```python\nT = ufloat(400, 5)  # 400 \u00b1 5\nP = ufloat(10, 1)   # 10 \u00b1 1\nresult = P / T      # Automatically tracks uncertainty!\n```\n\n### When Monte Carlo Is Necessary\n\nAnalytical propagation assumes small, symmetric uncertainties. Use Monte Carlo when:\n- Uncertainties are large\n- Distributions are non-normal (e.g., uniform, log-normal)\n- Functions are highly nonlinear\n- You need the full output distribution, not just mean \u00b1 std"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the uncertainties package (commonly used with pycse)\n",
    "from uncertainties import ufloat\n",
    "from uncertainties import umath\n",
    "\n",
    "# Define uncertain quantities\n",
    "T = ufloat(400, 5)     # Temperature: 400 \u00b1 5 K\n",
    "P = ufloat(10, 0.5)    # Pressure: 10 \u00b1 0.5 bar\n",
    "R = 8.314              # Gas constant (exact)\n",
    "\n",
    "# Ideal gas: n/V = P/(RT)\n",
    "# Convert P to Pa: P * 1e5\n",
    "concentration = (P * 1e5) / (R * T)\n",
    "\n",
    "print(\"Uncertainty Propagation Example:\")\n",
    "print(f\"  Temperature: {T}\")\n",
    "print(f\"  Pressure: {P} bar\")\n",
    "print(f\"  Concentration: {concentration:.2f} mol/m\u00b3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrhenius equation with uncertain parameters\n",
    "A = ufloat(1.2e8, 0.3e8)       # Pre-exponential factor\n",
    "Ea = ufloat(52000, 2000)       # Activation energy (J/mol)\n",
    "T = ufloat(450, 10)            # Temperature (K)\n",
    "R = 8.314\n",
    "\n",
    "# k = A * exp(-Ea/(R*T))\n",
    "k = A * umath.exp(-Ea / (R * T))\n",
    "\n",
    "print(\"Arrhenius Rate Constant:\")\n",
    "print(f\"  A = {A}\")\n",
    "print(f\"  Ea = {Ea} J/mol\")\n",
    "print(f\"  T = {T} K\")\n",
    "print(f\"  k = {k:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo uncertainty propagation\n",
    "np.random.seed(42)\n",
    "n_samples = 10000\n",
    "\n",
    "# Sample from distributions\n",
    "A_samples = np.random.normal(1.2e8, 0.3e8, n_samples)\n",
    "Ea_samples = np.random.normal(52000, 2000, n_samples)\n",
    "T_samples = np.random.normal(450, 10, n_samples)\n",
    "\n",
    "# Calculate k for each sample\n",
    "k_samples = A_samples * np.exp(-Ea_samples / (8.314 * T_samples))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(k_samples, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(x=np.mean(k_samples), color='r', linestyle='--', linewidth=2, label=f'Mean: {np.mean(k_samples):.2e}')\n",
    "plt.axvline(x=np.percentile(k_samples, 2.5), color='g', linestyle=':', linewidth=2)\n",
    "plt.axvline(x=np.percentile(k_samples, 97.5), color='g', linestyle=':', linewidth=2, label='95% CI')\n",
    "plt.xlabel('Rate Constant k')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Monte Carlo Uncertainty Propagation')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Monte Carlo Results:\")\n",
    "print(f\"  Mean k: {np.mean(k_samples):.3e}\")\n",
    "print(f\"  Std k: {np.std(k_samples):.3e}\")\n",
    "print(f\"  95% CI: [{np.percentile(k_samples, 2.5):.3e}, {np.percentile(k_samples, 97.5):.3e}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary: Uncertainty Quantification Toolkit\n\n### When to Use What\n\n| Situation | Recommended Method |\n|-----------|-------------------|\n| Linear regression parameters | `pycse.regress` |\n| Nonlinear fitting parameters | `pycse.nlinfit` |\n| Predictions with honest uncertainty | Gaussian Processes |\n| Simple error propagation | `uncertainties` package |\n| Complex or large uncertainties | Monte Carlo simulation |\n\n### Key Takeaways\n\n1. **Always report uncertainty**: A prediction without confidence limits is incomplete\n2. **Confidence intervals \u2260 prediction intervals**: Parameter uncertainty \u2260 outcome uncertainty\n3. **GPs grow uncertain far from data**: This is a feature, not a bug\n4. **Propagate uncertainty through calculations**: Inputs uncertain \u2192 outputs uncertain\n5. **Use Monte Carlo for complex cases**: When in doubt, sample\n\n### The Engineering Mindset\n\nIn research, we seek the \"true\" value. In engineering, we design for the worst case. Understanding uncertainty lets you:\n- Set appropriate safety factors\n- Make robust decisions\n- Plan experiments efficiently\n- Communicate confidence honestly\n\n### Common Pitfalls\n\n- Ignoring model uncertainty (only reporting parameter uncertainty)\n- Assuming normal distributions when data suggests otherwise\n- Over-interpreting GP uncertainty far from training data\n- Forgetting to propagate uncertainty to final decisions\n\n## Next Steps\n\nIn the final module, we'll learn about model interpretability\u2014understanding *why* models make their predictions, not just what they predict."
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## The Catalyst Crisis: Chapter 12 - \"What We Don't Know\"\n\n*A story about uncertainty, honesty, and building trust*\n\n---\n\n\"You're recommending we reject 40% of incoming catalyst lots.\"\n\nThe ChemCorp VP of Operations had joined the call\u2014someone none of them had met before. Senior enough to make decisions. Skeptical enough to question everything.\n\n\"Based on the clustering model, yes,\" Alex said.\n\n\"That's a $2 million annual cost. You're sure?\"\n\nThe question hung in the air. Was she sure? Her model had 0.92 R-squared. Her clusters were statistically significant. The evidence pointed clearly at the catalyst.\n\nBut *sure*?\n\n\"I'd like to show you the uncertainty in our predictions,\" Alex said.\n\nShe pulled up the Gaussian Process model she'd built as a complement to the Random Forest. Unlike the forest, the GP provided confidence intervals\u2014not just predictions, but estimates of how confident those predictions were.\n\n\"For batches using Cluster 1 catalyst, our predictions are tight. 95% confidence interval of plus or minus 3% yield.\" She clicked to the next plot. \"For Cluster 3 catalyst, the confidence interval is plus or minus 12%.\"\n\nThe VP frowned. \"So you're less certain about the bad catalyst?\"\n\n\"We have less data from those conditions. The model knows what it doesn't know.\" Alex highlighted the uncertainty bands. \"If you want to reduce this uncertainty, you could run controlled experiments\u2014deliberately use some Cluster 3 catalyst under carefully monitored conditions.\"\n\n\"You're suggesting we intentionally run bad batches?\"\n\n\"I'm suggesting you could learn more with a few planned experiments than with months of observational data. Right now, we're confident that Cluster 3 is worse. We're less confident about exactly how much worse, or whether operating conditions could compensate.\"\n\nThe room was quiet. This wasn't the clear answer they wanted. But it was the honest answer.\n\nThe VP surprised her. \"I appreciate that. Too many consultants pretend to certainty they don't have.\" He leaned back. \"We'll start with screening\u2014reject the obvious Cluster 3 lots. And we'll design an experiment for the borderline cases. Your team will help?\"\n\n\"Absolutely.\"\n\nAfter the call, Jordan found Alex at her desk, staring at the uncertainty plots.\n\n\"That was brave. Telling an executive you're not sure.\"\n\nAlex shrugged. \"I was sure about what I was sure about. And honest about what I wasn't. That's all we can do.\"\n\nShe added to the mystery board: **Uncertainty is information. High confidence in Cluster 1 recommendations. Lower confidence in Cluster 3\u2014need controlled experiments.**\n\n---\n\n*Continue to the final lecture for the resolution of the Catalyst Crisis...*",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}