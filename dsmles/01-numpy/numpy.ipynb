{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jkitchin/s26-06642/blob/main/dsmles/01-numpy/numpy.ipynb)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 01: NumPy Fundamentals\n",
    "\n",
    "NumPy is the foundation of numerical computing in Python. Nearly every data science library builds on NumPy arrays.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Create and manipulate NumPy arrays\n",
    "2. Use vectorized operations (no loops!)\n",
    "3. Apply broadcasting for efficient computation\n",
    "4. Perform basic linear algebra\n",
    "5. Generate random numbers for simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Why NumPy? The Foundation of Scientific Python\n\nBefore we dive in, it's worth understanding *why* NumPy exists and what problem it solves.\n\n### The Problem with Python Lists\n\nPython is a wonderful language, but it was designed for general-purpose programming, not numerical computing. Python lists are:\n\n- **Flexible**: Can hold mixed types (`[1, \"hello\", 3.14]`)\n- **Dynamic**: Can grow and shrink easily\n- **Slow**: Each element is a full Python object with overhead\n\nThis flexibility comes at a cost. When you're doing numerical work—solving differential equations, processing spectra, training machine learning models—you need to perform the *same operation on millions of numbers*. Python's flexibility becomes a liability.\n\n### NumPy's Solution\n\nNumPy provides a new data type: the **ndarray** (n-dimensional array). NumPy arrays are:\n\n- **Homogeneous**: All elements have the same type (e.g., all 64-bit floats)\n- **Contiguous**: Stored in a single block of memory\n- **Vectorized**: Operations apply to all elements at once, implemented in C\n\nThe result? NumPy can be 10-100x faster than Python lists for numerical operations.\n\n### Why This Matters for Chemical Engineering\n\nAlmost everything we do involves arrays of numbers:\n- Sensor data from reactors (time series of temperatures, pressures, flows)\n- Concentration profiles from simulations\n- Spectroscopic data (absorbance vs wavelength)\n- Training data for machine learning models\n\nNumPy is the foundation that Pandas, scikit-learn, TensorFlow, and virtually every scientific Python library builds upon. Master NumPy, and everything else becomes easier."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed comparison\n",
    "python_list = list(range(1000000))\n",
    "numpy_array = np.arange(1000000)\n",
    "\n",
    "# Python list\n",
    "%timeit [x**2 for x in python_list]\n",
    "\n",
    "# NumPy array\n",
    "%timeit numpy_array**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Creating Arrays: Choosing the Right Approach\n\nThere are many ways to create NumPy arrays, and the right choice depends on your situation:\n\n| Situation | Method | Example |\n|-----------|--------|---------|\n| From existing data | `np.array()` | Converting a Python list |\n| Initialize to zeros | `np.zeros()` | Pre-allocating for a loop |\n| Initialize to ones | `np.ones()` | Creating masks or weights |\n| Evenly spaced values | `np.linspace()` | Plotting a function |\n| Integer sequence | `np.arange()` | Loop indices |\n| Random values | `np.random.uniform()` | Monte Carlo simulation |\n\n**Pro tip**: Avoid growing arrays in loops. If you know the final size, pre-allocate with `np.zeros()` and fill in values. This is much faster than appending."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Python list\n",
    "concentrations = np.array([0.1, 0.2, 0.5, 1.0, 2.0])  # mol/L\n",
    "print(\"Concentrations:\", concentrations)\n",
    "print(\"Type:\", type(concentrations))\n",
    "print(\"Shape:\", concentrations.shape)\n",
    "print(\"Dtype:\", concentrations.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common array creation functions\n",
    "zeros = np.zeros(5)\n",
    "ones = np.ones(5)\n",
    "temps = np.linspace(300, 500, 5)  # 5 evenly spaced points from 300 to 500\n",
    "pressures = np.arange(1, 11, 2)   # From 1 to 11, step 2\n",
    "\n",
    "print(\"Zeros:\", zeros)\n",
    "print(\"Ones:\", ones)\n",
    "print(\"Temperatures:\", temps)\n",
    "print(\"Pressures:\", pressures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D arrays (matrices)\n",
    "# Experimental data: rows = experiments, columns = [T, P, yield]\n",
    "experiments = np.array([\n",
    "    [300, 1.0, 45.2],\n",
    "    [350, 1.5, 52.8],\n",
    "    [400, 2.0, 68.1],\n",
    "    [450, 2.5, 75.4],\n",
    "    [500, 3.0, 82.0]\n",
    "])\n",
    "\n",
    "print(\"Shape:\", experiments.shape)  # (5 rows, 3 columns)\n",
    "print(\"\\nExperiment data:\")\n",
    "print(experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Indexing and Slicing: Accessing Your Data\n\nNumPy's indexing is one of its most powerful features. Understanding it well will save you countless hours of writing loops.\n\n### The Key Insight\n\nIn Python, you typically write loops to process data. In NumPy, you **describe what you want**, and NumPy figures out how to get it efficiently.\n\nInstead of:\n```python\nresult = []\nfor i in range(len(data)):\n    if data[i] > threshold:\n        result.append(data[i])\n```\n\nYou write:\n```python\nresult = data[data > threshold]\n```\n\nThis isn't just shorter—it's 10-100x faster because the loop runs in compiled C code.\n\n### Types of Indexing\n\n1. **Basic indexing** (integers and slices): Returns views (no copy)\n2. **Advanced indexing** (boolean masks, integer arrays): Returns copies\n\nUnderstanding this distinction matters for performance and avoiding bugs."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D indexing\n",
    "temps = np.array([300, 350, 400, 450, 500])\n",
    "print(\"First element:\", temps[0])\n",
    "print(\"Last element:\", temps[-1])\n",
    "print(\"First three:\", temps[:3])\n",
    "print(\"Every other:\", temps[::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D indexing\n",
    "print(\"First row (experiment 1):\", experiments[0])\n",
    "print(\"First column (all temperatures):\", experiments[:, 0])\n",
    "print(\"Yields (third column):\", experiments[:, 2])\n",
    "print(\"Single element [2,1]:\", experiments[2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean indexing - very powerful!\n",
    "yields = experiments[:, 2]\n",
    "temps = experiments[:, 0]\n",
    "\n",
    "# Find experiments with yield > 60%\n",
    "high_yield = yields > 60\n",
    "print(\"High yield mask:\", high_yield)\n",
    "print(\"High yield values:\", yields[high_yield])\n",
    "print(\"Temps for high yield:\", temps[high_yield])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Vectorized Operations: Thinking in Arrays\n\nThis is the most important concept in NumPy. **Vectorization** means applying an operation to an entire array at once, rather than looping through elements.\n\n### Why Vectorization Matters\n\n1. **Speed**: Operations run in optimized C code, not interpreted Python\n2. **Clarity**: `y = A * np.exp(-Ea / (R * T))` is clearer than a 5-line loop\n3. **Fewer bugs**: No off-by-one errors, no forgetting to append\n\n### The Mental Shift\n\nIf you're coming from MATLAB, vectorization will feel natural. If you're coming from traditional programming, it requires a mental shift:\n\n**Loop thinking**: \"For each element, do this operation\"\n**Array thinking**: \"Apply this operation to all elements\"\n\nThe examples below demonstrate this shift. Notice how each calculation applies to entire arrays—no loops needed!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature conversion: K to °C\n",
    "temps_K = np.array([300, 350, 400, 450, 500])\n",
    "temps_C = temps_K - 273.15\n",
    "\n",
    "print(\"Kelvin:\", temps_K)\n",
    "print(\"Celsius:\", temps_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideal gas law: PV = nRT\n",
    "# Calculate molar volume V/n = RT/P\n",
    "\n",
    "R = 8.314  # J/(mol·K)\n",
    "T = np.linspace(300, 500, 5)  # K\n",
    "P = 101325  # Pa (1 atm)\n",
    "\n",
    "V_molar = R * T / P  # m³/mol\n",
    "V_molar_L = V_molar * 1000  # L/mol\n",
    "\n",
    "print(\"Temperature (K):\", T)\n",
    "print(\"Molar volume (L/mol):\", V_molar_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrhenius equation: k = A * exp(-Ea/RT)\n",
    "A = 1e13  # 1/s\n",
    "Ea = 80000  # J/mol\n",
    "R = 8.314  # J/(mol·K)\n",
    "T = np.linspace(300, 600, 100)\n",
    "\n",
    "k = A * np.exp(-Ea / (R * T))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(T, k)\n",
    "plt.xlabel('Temperature (K)')\n",
    "plt.ylabel('Rate constant k (1/s)')\n",
    "plt.title('Arrhenius Plot (linear)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogy(1000/T, k)\n",
    "plt.xlabel('1000/T (1/K)')\n",
    "plt.ylabel('Rate constant k (1/s)')\n",
    "plt.title('Arrhenius Plot (log scale)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Broadcasting: The Magic Behind NumPy's Elegance\n\nBroadcasting is NumPy's way of handling operations between arrays of different shapes. It's what allows you to write `array + 5` (adding a scalar to every element) or multiply a matrix by a vector.\n\n### How Broadcasting Works\n\nWhen NumPy sees arrays of different shapes, it tries to make them compatible by:\n1. Comparing dimensions from right to left\n2. Dimensions match if they're equal, or if one of them is 1\n3. Arrays with a dimension of 1 are \"stretched\" to match the other\n\n### A Chemical Engineering Example\n\nSuppose you want to calculate reaction rates at multiple temperatures AND multiple concentrations. Instead of writing nested loops, broadcasting does it in one line.\n\n**The key**: Reshape one array so dimensions can be broadcast. `k.reshape(-1, 1)` makes k a column vector (5×1), and `C` stays a row (1×4). NumPy broadcasts to create a 5×4 grid of all combinations."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate reaction rates at multiple T and C combinations\n",
    "T = np.array([300, 350, 400, 450, 500])  # 5 temperatures\n",
    "C = np.array([0.1, 0.5, 1.0, 2.0])  # 4 concentrations\n",
    "\n",
    "# Rate = k * C, where k depends on T\n",
    "k = A * np.exp(-Ea / (R * T))  # Shape: (5,)\n",
    "\n",
    "# We want a 5x4 array of rates\n",
    "# Reshape k to (5, 1) and C stays (4,) → broadcasts to (5, 4)\n",
    "rates = k.reshape(-1, 1) * C\n",
    "\n",
    "print(\"k shape:\", k.shape)\n",
    "print(\"C shape:\", C.shape)\n",
    "print(\"rates shape:\", rates.shape)\n",
    "print(\"\\nRates (rows=T, cols=C):\")\n",
    "print(rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated experimental yields\n",
    "yields = np.array([78.2, 82.1, 79.5, 81.3, 80.0, 79.8, 83.2, 77.9, 80.5, 81.1])\n",
    "\n",
    "print(f\"Mean: {np.mean(yields):.2f}%\")\n",
    "print(f\"Std: {np.std(yields):.2f}%\")\n",
    "print(f\"Min: {np.min(yields):.2f}%\")\n",
    "print(f\"Max: {np.max(yields):.2f}%\")\n",
    "print(f\"Median: {np.median(yields):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation along axes for 2D arrays\n",
    "# Rows = different catalysts, Cols = replicate experiments\n",
    "catalyst_yields = np.array([\n",
    "    [78, 82, 79, 81, 80],  # Catalyst A\n",
    "    [65, 68, 66, 64, 67],  # Catalyst B\n",
    "    [88, 91, 89, 87, 90],  # Catalyst C\n",
    "])\n",
    "\n",
    "print(\"Mean per catalyst (across replicates):\")\n",
    "print(np.mean(catalyst_yields, axis=1))  # axis=1 means across columns\n",
    "\n",
    "print(\"\\nMean per replicate (across catalysts):\")\n",
    "print(np.mean(catalyst_yields, axis=0))  # axis=0 means across rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving linear systems: Ax = b\n",
    "# Material balance: 3 reactions, 3 unknowns\n",
    "\n",
    "# Stoichiometric matrix\n",
    "A = np.array([\n",
    "    [1, -1, 0],\n",
    "    [0, 1, -1],\n",
    "    [1, 0, 1]\n",
    "])\n",
    "\n",
    "# Right-hand side (inlet flows)\n",
    "b = np.array([10, 5, 20])\n",
    "\n",
    "# Solve\n",
    "x = np.linalg.solve(A, b)\n",
    "print(\"Solution x:\", x)\n",
    "\n",
    "# Verify: Ax should equal b\n",
    "print(\"Verification A @ x:\", A @ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix operations\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "print(\"Determinant:\", np.linalg.det(A))\n",
    "print(\"\\nInverse:\")\n",
    "print(np.linalg.inv(A))\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "print(\"\\nEigenvalues:\", eigenvalues)\n",
    "print(\"\\nEigenvectors:\")\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Random Numbers: Essential for Simulation\n\nRandom number generation is fundamental to many scientific applications:\n\n- **Monte Carlo simulation**: Propagating uncertainty, sampling from distributions\n- **Machine learning**: Initializing weights, shuffling data, dropout\n- **Process simulation**: Modeling noise, disturbances, variability\n- **Experimental design**: Random sampling, bootstrap resampling\n\n### NumPy's Random Number Generator\n\nModern NumPy (1.17+) uses a new random number generator API. The recommended approach is:\n\n```python\nrng = np.random.default_rng(seed=42)  # Create a generator with a seed\n```\n\n**Why use a seed?** Seeds make your results reproducible. Running the same code twice with the same seed gives identical \"random\" numbers. This is essential for:\n- Debugging (reproducing exactly what happened)\n- Sharing results (others can reproduce your analysis)\n- Testing (consistent behavior across runs)\n\n**When NOT to seed**: When you genuinely need randomness (cryptography, production sampling)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Uniform random numbers\n",
    "uniform = rng.uniform(0, 1, 5)\n",
    "print(\"Uniform [0,1):\", uniform)\n",
    "\n",
    "# Normal distribution (Gaussian)\n",
    "normal = rng.normal(loc=50, scale=5, size=5)  # mean=50, std=5\n",
    "print(\"Normal (μ=50, σ=5):\", normal)\n",
    "\n",
    "# Random integers\n",
    "integers = rng.integers(1, 100, 5)\n",
    "print(\"Random integers [1, 100):\", integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo simulation: Propagating measurement uncertainty\n",
    "# Measure temperature: T = 400 ± 5 K\n",
    "# What's the uncertainty in rate constant k?\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "n_samples = 10000\n",
    "\n",
    "# Sample temperatures from normal distribution\n",
    "T_samples = rng.normal(400, 5, n_samples)\n",
    "\n",
    "# Calculate k for each sample\n",
    "k_samples = A * np.exp(-Ea / (R * T_samples))\n",
    "\n",
    "print(f\"k = {np.mean(k_samples):.4e} ± {np.std(k_samples):.4e}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axes[0].hist(T_samples, bins=50, edgecolor='black')\n",
    "axes[0].set_xlabel('Temperature (K)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Input: Temperature Distribution')\n",
    "\n",
    "axes[1].hist(k_samples, bins=50, edgecolor='black')\n",
    "axes[1].set_xlabel('Rate constant k (1/s)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Output: Rate Constant Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Common Pitfalls: Mistakes Everyone Makes\n\nNumPy has some non-obvious behaviors that trip up beginners (and sometimes experts). Understanding these will save you debugging time.\n\n### 1. Views vs Copies\n\nThis is the most common source of NumPy bugs. When you slice an array, you get a **view**, not a copy. Modifying the view modifies the original!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitfall 1: Views vs Copies\n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = a[1:4]  # This is a VIEW, not a copy!\n",
    "\n",
    "b[0] = 99  # This modifies 'a' too!\n",
    "print(\"a:\", a)  # [1, 99, 3, 4, 5]\n",
    "\n",
    "# Use .copy() if you need an independent copy\n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = a[1:4].copy()\n",
    "b[0] = 99\n",
    "print(\"a (with copy):\", a)  # [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitfall 2: Integer division\n",
    "a = np.array([1, 2, 3])  # Integer array\n",
    "print(\"Integer array / 2:\", a / 2)  # Fine, returns floats\n",
    "\n",
    "# But be careful with floor division\n",
    "print(\"Integer array // 2:\", a // 2)  # Integer division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pitfall 3: Shape mismatches\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([1, 2])  # Different length!\n",
    "\n",
    "try:\n",
    "    c = a + b\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary: NumPy Mindset\n\nNumPy requires a different way of thinking about computation. Here's what to remember:\n\n### Core Concepts\n\n| Concept | Key Idea | Why It Matters |\n|---------|----------|----------------|\n| **Arrays** | Homogeneous, typed containers | 10-100x faster than lists |\n| **Vectorization** | Operate on entire arrays | Eliminates slow Python loops |\n| **Broadcasting** | Automatic shape matching | Clean code, fewer bugs |\n| **Views** | Slices share memory | Fast, but be careful with modifications |\n\n### When to Use NumPy\n\n- Any numerical computation with arrays of numbers\n- Building blocks for machine learning features\n- Scientific calculations (physics, chemistry, engineering)\n- Image and signal processing\n\n### When to Use Pandas Instead\n\n- Tabular data with labeled columns\n- Mixed data types (numbers, strings, dates)\n- Time series with datetime indices\n- Data cleaning and exploration\n\n### Key Takeaways\n\n1. **Think in arrays**: Write operations that apply to whole arrays, not individual elements\n2. **Avoid loops**: If you're writing a for loop over array elements, there's probably a better way\n3. **Scale matters**: Always scale/normalize features before combining them\n4. **Copy when needed**: Use `.copy()` if you need to modify a slice without affecting the original\n5. **Seed for reproducibility**: Always set a random seed for reproducible results\n\n## Next Steps\n\nIn the next module, we'll learn Pandas, which builds on NumPy to provide labeled data structures for tabular data. If NumPy is the engine, Pandas is the dashboard—same power, but easier to interact with for real-world data."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}